---
title: "How to use cross-validation with the image data generator in Keras and TensorFlow"
draft: true
author: Shirin Glander
date: '2019-02-04'
categories: ["R", "keras"]
tags: ["R", "keras", "image classification", "tensorflow"]
thumbnailImagePosition: left
thumbnailImage: 
metaAlignment: center
coverMeta: out
slug: keras_fruits_crossvalidation
---



<blockquote>
<p>I’ve been using keras and TensorFlow for a while now - and love its simplicity and straight-forward way to modeling. As part of the latest update to my <a href="https://shirinsplayground.netlify.com/2018/05/deep_learning_keras_tensorflow_18_07/">Workshop about deep learning with R and keras</a> I’ve added a new example analysis:</p>
</blockquote>
<p><a href="https://shirinsplayground.netlify.com/2018/06/keras_fruits/" class="uri">https://shirinsplayground.netlify.com/2018/06/keras_fruits/</a></p>
<pre class="r"><code>library(keras)
library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ───────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.1.0     ✔ purrr   0.2.5
## ✔ tibble  2.0.1     ✔ dplyr   0.7.8
## ✔ tidyr   0.8.2     ✔ stringr 1.3.1
## ✔ readr   1.3.1     ✔ forcats 0.3.0</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.5.2</code></pre>
<pre><code>## ── Conflicts ──────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code># list of fruits to modle
fruit_list &lt;- c(&quot;Kiwi&quot;, &quot;Banana&quot;, &quot;Apricot&quot;, &quot;Avocado&quot;, &quot;Cocos&quot;, &quot;Clementine&quot;, &quot;Mandarine&quot;, &quot;Orange&quot;,
                &quot;Limes&quot;, &quot;Lemon&quot;, &quot;Peach&quot;, &quot;Plum&quot;, &quot;Raspberry&quot;, &quot;Strawberry&quot;, &quot;Pineapple&quot;, &quot;Pomegranate&quot;)

# number of output classes (i.e. fruits)
output_n &lt;- length(fruit_list)

# image size to scale down to (original images are 100 x 100 px)
img_width &lt;- 20
img_height &lt;- 20
target_size &lt;- c(img_width, img_height)

# RGB = 3 channels
channels &lt;- 3

# path to image folders
train_image_files_path &lt;- &quot;/Users/shiringlander/Documents/Github/DL_AI/Tutti_Frutti/fruits-360/Training/&quot;</code></pre>
<pre class="r"><code>train_data_gen = image_data_generator(
  rescale = 1/255,
  validation_split = 0.3
)</code></pre>
<pre class="r"><code># training images
train_image_array_gen &lt;- flow_images_from_directory(train_image_files_path, 
                                          train_data_gen,
                                          subset = &#39;training&#39;,
                                          target_size = target_size,
                                          class_mode = &quot;categorical&quot;,
                                          classes = fruit_list,
                                          seed = 42)

# validation images
valid_image_array_gen &lt;- flow_images_from_directory(train_image_files_path, 
                                          train_data_gen,
                                          subset = &#39;validation&#39;,
                                          target_size = target_size,
                                          class_mode = &quot;categorical&quot;,
                                          classes = fruit_list,
                                          seed = 42)</code></pre>
<pre class="r"><code>cat(&quot;Number of images per class:&quot;)</code></pre>
<pre><code>## Number of images per class:</code></pre>
<pre class="r"><code>table(factor(train_image_array_gen$classes))</code></pre>
<pre><code>## 
##   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15 
## 327 343 345 299 343 343 343 336 343 345 345 313 343 345 343 345</code></pre>
<pre class="r"><code>cat(&quot;\nClass label vs index mapping:\n&quot;)</code></pre>
<pre><code>## 
## Class label vs index mapping:</code></pre>
<pre class="r"><code>train_image_array_gen$class_indices</code></pre>
<pre><code>## $Lemon
## [1] 9
## 
## $Peach
## [1] 10
## 
## $Limes
## [1] 8
## 
## $Apricot
## [1] 2
## 
## $Plum
## [1] 11
## 
## $Avocado
## [1] 3
## 
## $Strawberry
## [1] 13
## 
## $Pineapple
## [1] 14
## 
## $Orange
## [1] 7
## 
## $Mandarine
## [1] 6
## 
## $Banana
## [1] 1
## 
## $Clementine
## [1] 5
## 
## $Kiwi
## [1] 0
## 
## $Cocos
## [1] 4
## 
## $Pomegranate
## [1] 15
## 
## $Raspberry
## [1] 12</code></pre>
<div id="define-model" class="section level3">
<h3>Define model</h3>
<pre class="r"><code># number of training samples
train_samples &lt;- train_image_array_gen$n
# number of validation samples
valid_samples &lt;- valid_image_array_gen$n

# define batch size and number of epochs
batch_size &lt;- 32
epochs &lt;- 10</code></pre>
<pre class="r"><code># initialise model
model &lt;- keras_model_sequential()

# add layers
model %&gt;%
  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = &quot;same&quot;, input_shape = c(img_width, img_height, channels)) %&gt;%
  layer_activation(&quot;relu&quot;) %&gt;%
  
  # Second hidden layer
  layer_conv_2d(filter = 16, kernel_size = c(3,3), padding = &quot;same&quot;) %&gt;%
  layer_activation_leaky_relu(0.5) %&gt;%
  layer_batch_normalization() %&gt;%

  # Use max pooling
  layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%
  layer_dropout(0.25) %&gt;%
  
  # Flatten max filtered output into feature vector 
  # and feed into dense layer
  layer_flatten() %&gt;%
  layer_dense(100) %&gt;%
  layer_activation(&quot;relu&quot;) %&gt;%
  layer_dropout(0.5) %&gt;%

  # Outputs from dense layer are projected onto output layer
  layer_dense(output_n) %&gt;% 
  layer_activation(&quot;softmax&quot;)

# compile
model %&gt;% compile(
  loss = &quot;categorical_crossentropy&quot;,
  optimizer = optimizer_rmsprop(lr = 0.0001, decay = 1e-6),
  metrics = &quot;accuracy&quot;
)</code></pre>
<pre class="r"><code># fit
hist &lt;- model %&gt;% fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = epochs, 
  
  # validation data
  validation_data = valid_image_array_gen,
  validation_steps = as.integer(valid_samples / batch_size)
)</code></pre>
<pre class="r"><code>plot(hist)</code></pre>
<p><img src="/post/2019-02-04_keras_fruits_crossvalidation_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>test_image_files_path = &quot;/Users/shiringlander/Documents/Github/DL_AI/Tutti_Frutti/fruits-360/Validation/&quot;

test_datagen &lt;- image_data_generator(rescale = 1/255)

test_generator &lt;- flow_images_from_directory(
        test_image_files_path,
        test_datagen,
        target_size = target_size,
        class_mode = &quot;categorical&quot;,
        classes = fruit_list,
        seed = 42)</code></pre>
<pre class="r"><code>indices &lt;- train_image_array_gen$class_indices %&gt;%
  as.data.frame() %&gt;%
  gather() %&gt;%
  arrange(value)</code></pre>
<pre class="r"><code>predictions &lt;- as.data.frame(predict_generator(model, test_generator, steps = as.integer(test_generator$n / batch_size)))</code></pre>
<pre class="r"><code>colnames(predictions) &lt;- indices$key
predictions &lt;- predictions %&gt;%
  mutate(truth_idx = test_generator$classes) %&gt;%
  left_join(indices, by = c(&quot;truth_idx&quot; = &quot;value&quot;)) %&gt;%
  rename(truth_lbl = key)</code></pre>
<pre class="r"><code>predictions %&gt;%
  mutate(id = seq(1:test_generator$n)) %&gt;%
  gather(pred_lbl, y, Kiwi:Pomegranate) %&gt;%
  ggplot(aes(x = id, y = y), color = truth_lbl) +
    facet_wrap( ~ pred_lbl, scales = &quot;free&quot;, ncol = 2) +
    geom_jitter()</code></pre>
<pre class="r"><code>evaluate_generator(model, test_generator, steps = as.integer(test_generator$n / batch_size))</code></pre>
<pre><code>## $loss
## [1] 0.02518432
## 
## $acc
## [1] 0.9907407</code></pre>
<hr />
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS  10.14.2
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] bindrcpp_0.2.2  forcats_0.3.0   stringr_1.3.1   dplyr_0.7.8    
##  [5] purrr_0.2.5     readr_1.3.1     tidyr_0.8.2     tibble_2.0.1   
##  [9] ggplot2_3.1.0   tidyverse_1.2.1 keras_2.2.4    
## 
## loaded via a namespace (and not attached):
##  [1] reticulate_1.10  tidyselect_0.2.5 xfun_0.4         reshape2_1.4.3  
##  [5] haven_2.0.0      lattice_0.20-38  colorspace_1.4-0 generics_0.0.2  
##  [9] htmltools_0.3.6  yaml_2.2.0       base64enc_0.1-3  rlang_0.3.1     
## [13] pillar_1.3.1     withr_2.1.2      glue_1.3.0       readxl_1.2.0    
## [17] modelr_0.1.2     bindr_0.1.1      plyr_1.8.4       tensorflow_1.10 
## [21] cellranger_1.1.0 munsell_0.5.0    blogdown_0.10    gtable_0.2.0    
## [25] rvest_0.3.2      evaluate_0.12    labeling_0.3     knitr_1.21      
## [29] tfruns_1.4       broom_0.5.1      Rcpp_1.0.0       backports_1.1.3 
## [33] scales_1.0.0     jsonlite_1.6     hms_0.4.2        digest_0.6.18   
## [37] stringi_1.2.4    bookdown_0.9     grid_3.5.1       cli_1.0.1       
## [41] tools_3.5.1      magrittr_1.5     lazyeval_0.2.1   crayon_1.3.4    
## [45] whisker_0.3-2    pkgconfig_2.0.2  zeallot_0.1.0    Matrix_1.2-15   
## [49] xml2_1.2.0       lubridate_1.7.4  rstudioapi_0.9.0 assertthat_0.2.0
## [53] rmarkdown_1.11   httr_1.4.0       R6_2.3.0         nlme_3.1-137    
## [57] compiler_3.5.1</code></pre>
</div>
