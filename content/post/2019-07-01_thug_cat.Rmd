---
title: "codecentric.AI Thug Cat Project in R: keypoint regression with Keras"
draft: true
author: Shirin Glander
date: '2019-07-01'
categories: ["R", "codecentric.AI"]
tags: ["R", "codecentric.AI", "Keras", "TensorFlow"]
thumbnailImagePosition: left
thumbnailImage: 
metaAlignment: center
coverMeta: out
slug: thug_cat_r
---

https://bootcamp.codecentric.ai/

Module 5: Neural Nets and Deep Learning
Lesson 5.10: Thug Cat Project
https://bootcamp.codecentric.ai/dl-course/module/5/43/

## The data

https://www.kaggle.com/crawford/cat-dataset

> The CAT dataset includes over 9,000 cat images. For each image, there are annotations of the head of cat with nine points, two for eyes, one for mouth, and six for ears.

> Weiwei Zhang, Jian Sun, and Xiaoou Tang, Cat Head Detection - How to Effectively Exploit Shape and Texture Features, Proc. of European Conf. Computer Vision, vol. 4, pp.802-816, 2008.

> The annotation data are stored in a file with the name of the corresponding image plus ."cat" at the end. There is one annotation file for each cat image. For each annotation file, the annotation data are stored in the following sequence:

- number of points
- Left Eye
- Right Eye
- Mouth
- Left Ear-1
- Left Ear-2
- Left Ear-3
- Right Ear-1
- Right Ear-2
- Right Ear-3

```{r message = FALSE, warning=FALSE}
library(tidyverse)
path_to_images <- "/Users/shiringlander/Documents/Github/Data/cats/"
list_of_cat_images <- list.files(path_to_images, full.names = TRUE, recursive = TRUE, include.dirs = TRUE, pattern = "*.jpg$")
list_of_cat_annos <- list.files(path_to_images, full.names = TRUE, recursive = TRUE, include.dirs = TRUE, pattern = "*.cat$")

length(list_of_cat_images) == length(list_of_cat_annos)
length(list_of_cat_images)
head(list_of_cat_images)
```

```{r message = FALSE, warning=FALSE}
library(imager)
img <- list_of_cat_images[1]
image <- load.image(img)
dim(image)

library(readr)
keypoints = c("no_kps", 
              "lft_eye_x", "lft_eye_y", 
              "rgt_eye_x", "rgt_eye_y",
              "mouth_x", "mouth_y",
              "lft_ear_1_x", "lft_ear_1_y",
              "lft_ear_2_x", "lft_ear_2_y",
              "lft_ear_3_x", "lft_ear_3_y", 
              "rgt_ear_1_x", "rgt_ear_1_y", 
              "rgt_ear_2_x", "rgt_ear_2_y",
              "rgt_ear_3_x", "rgt_ear_3_y")

pts <- gsub(".jpg", ".jpg.cat", img)
points <- read_delim(pts, delim = " ", col_names = keypoints)

plot(image)
points(points[, grepl("_x", colnames(points))], points[, grepl("_y", colnames(points))])
```

## Predict only mouth

### Crop images to same height and width and combine into one array

- Convert keypoints into heatmap (1 heatmap per keypoint, starting with mouth)

```{r}
return_keypoints <- function(filename){
  pts <- gsub(".jpg", ".jpg.cat", filename)
  points <- read_delim(pts, delim = " ", col_names = keypoints) %>%
    slice(1) %>% 
    unlist(., use.names = TRUE)
  return(points)
}
```

```{r}
image_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/image_crop_array.rds")
heatmap_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/heatmap_crop_array.rds")
```

```{r}
str(heatmap_crop_array)
```

```{r warning=FALSE, message=FALSE, eval=FALSE}
library(matlab)
library(abind)

for (i in 1564:length(list_of_cat_images)) {
  img <- list_of_cat_images[i]
  image <- load.image(img)
  image <- grayscale(image, method = "Luma", drop = TRUE)
  
  w <- dim(image)[1]
  h <- dim(image)[2]
  
  heatmap <- matrix(0, nrow = w, ncol = h)
  kps_mouth <- return_keypoints(img)[6:7]
  heatmap[kps_mouth[1], kps_mouth[2]] <- 1
  
  image <- padarray(as.matrix(image), c(300, 300), padval=0, direction = "both")
  heatmap <- padarray(heatmap, c(300, 300), padval=0, direction = "both")
  
  kps_mouth[1] <- which(heatmap == 1, arr.ind=TRUE)[1]
  kps_mouth[2] <- which(heatmap == 1, arr.ind=TRUE)[2]
  
  rdm_1 <- sample(5:112, 1)
  rdm_2 <- sample(5:112, 1)
  
  min_w <- kps_mouth[1] - rdm_1
  max_w <- kps_mouth[1] + 223 - rdm_1
  
  min_h <- kps_mouth[2] - rdm_2
  max_h <- kps_mouth[2] + 223 - rdm_2
  
  image_resize <- image[min_w:max_w, min_h:max_h]
  heatmap_resize <- heatmap[min_w:max_w, min_h:max_h]
  
  img_id <- gsub("/Users/shiringlander/Documents/Github/Data/cats//", "", img)
  
  if (i == 1) {
    image_crop_array <- abind(image_resize, along = 0)
    attr(image_crop_array, "dimnames")[[1]] <- c(img_id)
    
    heatmap_crop_array <- abind(heatmap_resize, along = 0)
    attr(heatmap_crop_array, "dimnames")[[1]] <- c(img_id)
    
  } else {
    image_resize <- abind(image_resize, along = 0)
    image_crop_array <- abind(image_crop_array, image_resize, along = 1)
    attr(image_crop_array, "dimnames")[[1]][i] <- c(img_id)
    
    heatmap_resize <- abind(heatmap_resize, along = 0)
    heatmap_crop_array <- abind(heatmap_crop_array, heatmap_resize, along = 1)
    attr(heatmap_crop_array, "dimnames")[[1]][i] <- c(img_id)
  }
  
  if (i %% 10 == 0) {
    cat("Image", i, "\n")
  }
}

saveRDS(image_crop_array, file = "/Users/shiringlander/Documents/Github/shirinsplayground/data/image_crop_array.rds")
saveRDS(heatmap_crop_array, file = "/Users/shiringlander/Documents/Github/shirinsplayground/data/heatmap_crop_array.rds")
```

```{r}
image_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/image_crop_array.rds")
heatmap_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/heatmap_crop_array.rds")
```

```{r}
image_crop_array <- image_crop_array[which(attr(image_crop_array, "dimnames")[[1]] %in% attr(heatmap_crop_array, "dimnames")[[1]]), , ]
```

```{r}
dim(image_crop_array)
dim(heatmap_crop_array)

min(image_crop_array)
max(image_crop_array)

min(heatmap_crop_array)
max(heatmap_crop_array)
```

```{r warning=FALSE, message=FALSE}
mouth_label_x <- rep(NA, dim(heatmap_crop_array)[1])
mouth_label_y <- rep(NA, dim(heatmap_crop_array)[1])

for(i in 1:dim(heatmap_crop_array)[1]) {
  img <- attr(heatmap_crop_array, "dimnames")[[1]][i]
  heatmap <- heatmap_crop_array[i, , ]

  mouth_label_x[i] <- which(heatmap == 1, arr.ind=TRUE)[1]
  mouth_label_y[i] <- which(heatmap == 1, arr.ind=TRUE)[2]
}

names(mouth_label_x) <- attr(image_crop_array, "dimnames")[[1]]
names(mouth_label_y) <- attr(image_crop_array, "dimnames")[[1]]
```

- Split into training and test data

```{r}
x_train <- image_crop_array[1:1500, , ]
y_train <- heatmap_crop_array[1:1500, , ]
x_test <- image_crop_array[1501:2012, , ]
y_test <- heatmap_crop_array[1501:2012, , ]

y_train_lbl_x <- mouth_label_x[1:1500]
y_train_lbl_y <- mouth_label_y[1:1500]
y_test_lbl_x <- mouth_label_x[1501:2012]
y_test_lbl_y <- mouth_label_y[1501:2012]
```

```{r}
library(keras)

x_train <- array_reshape(x_train, c(1500, 224, 224, 1))
y_train <- array_reshape(y_train, c(1500, 224, 224, 1))
x_test <- array_reshape(x_test, c(512, 224, 224, 1))
y_test <- array_reshape(y_test, c(512, 224, 224, 1))
```

```{r}
model <- keras_model_sequential() %>%
 
  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = "same", input_shape = c(224, 224, 1)) %>%
  layer_activation("relu") %>%

  layer_conv_2d(filter = 1, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("sigmoid")

model %>% compile(
  loss = "mse",
  optimizer = "adam",
  metrics = c("mae", "mse")
)

model
```

```{r}
history <- model %>% fit(
    x_train, 
    y_train,
    validation_split = 0.2,
    batch_size = 10,
    epochs = 3
)
```

```{r}
plot(history)
```

```{r}
results <- model %>% 
  evaluate(x_test, y_test)
results
```

```{r}
image_test <- x_test[1, , , ]
dim(image_test)
image(image_test)
```

```{r}
image_test <- array_reshape(image_test, c(1, 224, 224, 1))
heatmap_pred <- model %>% predict(image_test)
str(heatmap_pred)
image(heatmap_pred[1, , , ], col = gray.colors(10))
```

```{r}
image(round(heatmap_pred[1, , ,]), col = gray.colors(10))
```

```{r}
k_clear_session()
```

```{r}
model_input <- layer_input(shape = c(224, 224, 1), dtype = 'float32', name = 'image_input')

predictions <- 
  model_input %>%
  layer_activation("relu") %>%
  
  layer_flatten() %>%
  layer_dense(10) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5)

output_y1 <- 
  predictions %>%
  layer_dense(units = 1, activation = "linear", name = "output_y1")

output_y2 <-
  predictions %>%
  layer_dense(units = 1, activation = "linear", name = "output_y2")

model <- keras_model(
  inputs = model_input,
  outputs = c(output_y1, output_y2)
)

model 
```

```{r}
model %>%
  compile(loss = 'mean_squared_error', # MSE for continuous output
          loss_weights = c(0.5, 0.5), # Weight both coords equally 
          optimizer = optimizer_adam())
```

```{r}
history <- model %>% fit(
    x = x_train, 
    y = list(y_train_lbl_x, y_train_lbl_y),
    validation_split = 0.2,
    batch_size = 10,
    epochs = 3
)
```

```{r}
results <- model %>% 
  evaluate(x_test, list(y_test_lbl_x, y_test_lbl_y))
results
```

```{r}
image_test <- array_reshape(image_test, c(1, 224, 224, 1))
coords_pred <- model %>% predict(image_test)
coords_pred
```

```{r}
image_test <- x_test[1, , , ]
image(image_test)
points(coords_pred[[1]], coords_pred[[2]])
```

