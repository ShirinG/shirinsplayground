---
title: "codecentric.AI Thug Cat Project in R: keypoint regression with Keras"
draft: true
author: Shirin Elsinghorst
date: '2019-07-01'
categories: ["R", "codecentric.AI"]
tags: ["R", "codecentric.AI", "Keras", "TensorFlow"]
thumbnailImagePosition: left
thumbnailImage: 
metaAlignment: center
coverMeta: out
slug: thug_cat_r
---

https://bootcamp.codecentric.ai/

Module 5: Neural Nets and Deep Learning
Lesson 5.10: Thug Cat Project
https://bootcamp.codecentric.ai/dl-course/module/5/43/

## The data

## Predict only mouth

```{r}
image_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/image_crop_array.rds")
heatmap_crop_array <- readRDS("/Users/shiringlander/Documents/Github/shirinsplayground/data/heatmap_crop_array.rds")
```

```{r warning=FALSE, message=FALSE}
mouth_label_x <- rep(NA, dim(heatmap_crop_array)[1])
mouth_label_y <- rep(NA, dim(heatmap_crop_array)[1])

for(i in 1:dim(heatmap_crop_array)[1]) {
  img <- attr(heatmap_crop_array, "dimnames")[[1]][i]
  heatmap <- heatmap_crop_array[i, , ]

  mouth_label_x[i] <- which(heatmap == 1, arr.ind=TRUE)[1]
  mouth_label_y[i] <- which(heatmap == 1, arr.ind=TRUE)[2]
}

names(mouth_label_x) <- attr(image_crop_array, "dimnames")[[1]]
names(mouth_label_y) <- attr(image_crop_array, "dimnames")[[1]]
```

## Train with multi-output on x and y coordinates

- Split into training and test data

```{r}
x_train <- image_crop_array[1:2000, , ]
x_test <- image_crop_array[2001:2014, , ]
```

```{r}
library(keras)

x_train <- array_reshape(x_train, c(2000, 224, 224, 1))
y_train <- array_reshape(y_train, c(2000, 224, 224, 1))
```

```{r}
y_train_lbl_x <- mouth_label_x[1:2000]
y_train_lbl_y <- mouth_label_y[1:2000]
y_test_lbl_x <- mouth_label_x[2001:2014]
y_test_lbl_y <- mouth_label_y[2001:2014]
```

```{r}
model_input <- layer_input(shape = c(224, 224, 1), dtype = 'float32', name = 'image_input')

predictions <- 
  model_input %>%
  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%

  layer_conv_2d(filter = 1, kernel_size = c(3,3), padding = "same") %>%
  layer_activation("relu") %>%
  
  layer_flatten() %>%
  layer_dense(10) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5)

output_y1 <- 
  predictions %>%
  layer_dense(units = 1, activation = "linear", name = "output_y1")

output_y2 <-
  predictions %>%
  layer_dense(units = 1, activation = "linear", name = "output_y2")

model <- keras_model(
  inputs = model_input,
  outputs = c(output_y1, output_y2)
)

model 
```

```{r}
model %>%
  compile(loss = 'mean_squared_error', # MSE for continuous output
          loss_weights = c(0.5, 0.5), # Weight both coords equally 
          optimizer = optimizer_adam())
```

```{r}
history <- model %>% fit(
    x = x_train, 
    y = list(y_train_lbl_x, y_train_lbl_y),
    validation_split = 0.2,
    batch_size = 10,
    epochs = 3
)
```

```{r}
plot(history)
```

```{r}
results <- model %>% 
  evaluate(x_test, list(y_test_lbl_x, y_test_lbl_y))
results
```

```{r}
coords_pred <- model %>% predict(image_test)
coords_pred
```

```{r}
image_test <- x_test[1, , , ]
image(image_test)
points(coords_pred[[1]], coords_pred[[2]])
```

