---
title: "Update to The Good, the Bad and the Ugly: how (not) to visualize Machine Learning data"
draft: true
author: Dr. Shirin Elsinghorst
date: '2021-04-28'
categories: ["R"]
tags: ["R", "ggplot2"]
thumbnailImagePosition: left
thumbnailImage: post/2020-10-20_goodbadugly_files/figure-html/unnamed-chunk-29-1.png
metaAlignment: center
coverMeta: out
slug: goodbadugly_ml
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Below you'll find the complete code used to create the **ggplot2** graphs in my talk **The Good, the Bad and the Ugly: how (not) to visualize Machine Learning data** at this year's Minds Mastering machines conference. You can find the German [slides here](https://docs.google.com/presentation/d/e/2PACX-1vR4pD2EmW9Gzxr1Q3qwgjEYkU64o2-ThlX1mXqfNQ2EKteVUVt6Qg2ImEKKi9XLv-Iutb3lD8esLyU7/pub?start=false&loop=false&delayms=3000):

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vR4pD2EmW9Gzxr1Q3qwgjEYkU64o2-ThlX1mXqfNQ2EKteVUVt6Qg2ImEKKi9XLv-Iutb3lD8esLyU7/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

You can find [Part 1: **The Good, the Bad and the Ugly: how (not) to visualize data** here](https://shirinsplayground.netlify.app/2020/10/goodbadugly/).

---

If you have questions or would like to talk about this article (or something else data-related), you can now [book 15-minute timeslots](https://shirinsplayground.netlify.app/page/bookme/) with me (it's free - one slot available per weekday): 

<img src="https://www.appointletcdn.com/loader/buttons/F62459.png" data-appointlet-organization="shirin-elsinghorst" data-appointlet-service="357892"><script src="https://www.appointletcdn.com/loader/loader.min.js" async="" defer=""></script>

*If you have been enjoying my content and would like to help me be able to create more, please consider sending me a donation at <button>[paypal.me](https://paypal.me/ShirinGlander)</button>. Thank you!* :-)

---

```{r libraries}
library(tidyverse)
library(mlbench)
library(ggfortify)
library(GGally)
library(scagnostics)
library(mlr) 
```

## Dataset

Pima Indians Diabetes dataset from [*mlbench* package](http://search.r-project.org/library/mlbench/html/PimaIndiansDiabetes.html).

```{r}
data(PimaIndiansDiabetes)
PimaIndiansDiabetes %>%
  head()
```

## Colors

- set [colorblind-friendly palettes](https://jfly.uni-koeln.de/color/)

```{r}
# The palette with grey:
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r}
ggplot <- function(...) ggplot2::ggplot(...) + 
  scale_color_manual(values = cbp1) +
  scale_fill_manual(values = cbp1) + # note: needs to be overridden when using continuous color scales
  theme_bw()
```

## Visualizing Machine Learning models



At each of these steps, data visualization helps the data scientist explore the data, understand the data and process the data to set it up for modeling.


Data visualization tools enable data scientists to quickly identify and focus on the most important data and the most important paths to take. Even during the modeling process, model graphs can help to speed up the model-creation process by displaying the model maps conceptually. 

https://arxiv.org/pdf/1801.06889.pdf

Visualizing models, decision boundaries and prediction results may give hints whether the model is indeed a good fit or it is a poor fit for the data. For example, it is high bias to ignore the nature of our data if use a straight line to fit a circular scatter of dots.
Researchers even visualized different optimizers to see their descend to minimize loss.

As part of any Data Science project, Data Visualization plays an important part in order to learn more about the available data and to identify any main pattern.

Data Visualization is Essential in Every Step of Machine Learning

Transform data into visual encodings
What is it good for?
Data exploration
Scientific insight
Communication
Education
How to ensure it works well?
Engage the visual system in smart ways
Take advantage of pre-attentive processing 

Find visual encodings that
â— Guide viewer's attention
â— Communicate data to the viewer
â— Let viewer calculate with data
On computer
â— Interactive exploration

Framework: visualization uses in ML
1. Training Data
2. Model Performance
3. Interpretability + model inspection
4. High-dimensional data
5. Education and communication 

Main approaches
Linear
- Principal Component Analysis (show as much variation in data as possible)
- Visualization of Labeled Data Using Linear Transformations (clusters match labels)

Non-linear (just a few of many) Minimize distortion, according to some metric
- Multidimensional scaling
- Sammon mapping
- Isomap
- t-SNE
- UMAP: New kid on the block Faster than t-SNE, Can efficiently embed into high dimensions (i.e. useful not just for visualization), Often seems to capture global structure better


### Exploratory Data Analysis

Exploratory Data Analysis (EDA) is the backbone of data analysis, including those that result in a machine learning model. EDA helps us to understand the data we are working with and put it into context, so that we are able to ask the right questions (or to put our questions into the right frame). It helps us take appropriate measures for cleaning, normalization/transformation, dealing with missing values, feature preparation and engineering, etc. Particularly if our machine learning model is trained on a limited dataset (but not only then!), appropriate data preparation can vastly improve the machine learning process: models will often train faster and achieve higher accuracy.

An essential part of EDA is data visualization. 

Typically, we want to start by exploring potential sources of errors in our data, like

- **wrong/useless data types** (sometimes data types are automatically set in a way that is not useful for our analysis, like *factors* versus *strings*, or wrong/strange entries in an otherwise numeric column will make it categorical)
- **missing values** (a collection of ways to visualize missingness can be found [here](https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html)),
- **outliers** (for example by plotting a box-plot of continuous variables)

Depending on the number of features/variables we have, it makes sense to look at them all individually and in correlation with each other. Depending on whether we have a categorical or continuous variable, we might be interested in properties that are shown by 

- **histograms** (frequency distribution of binned continuous variables),
- **density distribution** (normalized distribution of continuous variables) or 
- **bar-plots** (shows counts of categorical variables).

If our target variable is categorical, we will want to look at potential imbalances between the classes. Class imbalance will strongly affect the machine learning modeling process and will require us to consider up-/downsampling or similar techniques before we train a model.

Correlation analysis can show us, for example

- how our **target/dependent variable correlates with the remaining features** (often, just by looking at the correlation, we can identify one ore more feature that will have a strong impact on predicting the target because they are strongly correlated) or
- whether some of the **independent variables/features correlate with each other** (multicolinearity; we might want to consider removing strongly correlated features, so that they won't contribute the "same" information multiple times to the model and thus lead to overfitting).

Additional methods can be used to visualize groups of correlated features. These methods are often especially useful if we have a large dataset with a large feature set (highly dimensional data). Some of these methods for visualizing groups of correlated features and/or for comparing multiple variables and visualizing their relationships are:

- Dimensionality reduction, e.g. Principal Component Analysis (PCA), multidimensional scaling, T-SNE or UMAP
- Parallel coordinate plot
- Scatterplot matrix
- [scagnostics](https://cran.r-project.org/web/packages/scagnostics/index.html)

```{r}
# in our dataset,
# continuous variables are
PimaIndiansDiabetes %>%
  select(where(is.numeric)) %>%
  head()

# 'diabetes' is the only categorical variable is also our target or dependent variable
PimaIndiansDiabetes %>%
  select(!where(is.numeric)) %>%
  head()
```

```{r}
# boxplot of features
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_boxplot(alpha = 0.8)
```

```{r}
# bar plot of target
PimaIndiansDiabetes %>%
  ggplot(aes(x = diabetes, fill = diabetes)) +
    geom_bar(alpha = 0.8)
```

```{r}
# histogram of features
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_histogram(alpha = 0.8)
```

```{r}
# histogram of feature
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_density(alpha = 0.8)
```

```{r}
# correlation plot of features
mat <- PimaIndiansDiabetes %>%
  select(where(is.numeric))

cormat <- round(cor(mat), 2)

cormat <- cormat %>%
  as_data_frame() %>%
  mutate(x = colnames(mat)) %>%
  gather(key = "y", value = "value", pregnant:age)

cormat %>%
    remove_missing() %>%
    arrange(x, y) %>%
    ggplot(aes(x = x, y = y, fill = value)) + 
    geom_tile() +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
     midpoint = 0, limit = c(-1,1), space = "Lab", 
     name = "Pearson\nCorrelation") +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
    coord_fixed()
```

```{r}
# PCA
prep <- PimaIndiansDiabetes %>%
  select(where(is.numeric))

pca <- prep %>%
  prcomp(scale. = TRUE)

autoplot(pca, 
                data = PimaIndiansDiabetes, 
                colour = 'diabetes',
                shape = 'diabetes',
                loadings = TRUE, 
                loadings.colour = 'blue',
                loadings.label = TRUE, 
                loadings.label.size = 3) +
      scale_color_manual(values = cbp1) +
  scale_fill_manual(values = cbp1) +
  theme_bw()
```

```{r}
# parallel coordinate plots
ggparcoord(data = PimaIndiansDiabetes, 
           columns = c(1:8), 
           groupColumn = 9,
           scale = "robust",
           order = "skewness",
           alpha = 0.7)
```

```{r}
# scatterplot matrix
ggpairs(PimaIndiansDiabetes, 
        columns = c(1:8),
        alpha = 0.7)
```

```{r}
# scagnostics
scagnostics_dataset <- scagnostics(PimaIndiansDiabetes)

# scagnostics grid
scagnostics_grid_dataset <- scagnosticsGrid(scagnostics_dataset)

# outliers
scagnostics_o_dataset <- scagnosticsOutliers(scagnostics_dataset)
scagnostics_o_dataset[scagnostics_o_dataset]
outlier <- scagnostics_grid_dataset[scagnostics_o_dataset,]

# scagnostics exemplars
scagnostics_ex_dataset <- scagnosticsExemplars(scagnostics_dataset)
scagnostics_ex_dataset[scagnostics_ex_dataset]
exemplars <- scagnostics_grid_dataset[scagnostics_ex_dataset,]
```

### Training a machine learning model

```{r}
set.seed(1000) 

train_index <- sample(1:nrow(PimaIndiansDiabetes), 0.8 * nrow(PimaIndiansDiabetes)) 
test_index <- setdiff(1:nrow(PimaIndiansDiabetes), train_index) 

train <- PimaIndiansDiabetes[train_index,] 
test <- PimaIndiansDiabetes[test_index,]

list( train = summary(train), test = summary(test) )

(dt_task <- makeClassifTask(data=train, target="diabetes"))
(dt_prob <- makeLearner('classif.rpart', predict.type="prob"))
```

### Feature Selection
In order to select which features provide the best chance to predict Positive, the generateFilterValuesData gives us a score for each feature. This can then be plotted with PlotFilterValues. The score for each variable is dependent upon which criteria you choose. Here I choose Information Gain, Chi-squared and Gain Ratio as my criteria.

```{r}
library(FSelector)
generateFilterValuesData(dt_task, method = "information.gain") %>% plotFilterValues()
```

The generateFeatureImportanceData function also works in a similar fashion. Except it will show us the importance of each feature according to a given performance criteria. I have chosen True Positive Rate and Area Under the Curve.

```{r}
generateFeatureImportanceData(task=dt_task, learner = dt_prob,measure = tpr, interaction = FALSE)
generateFeatureImportanceData(task=dt_task, learner = dt_prob,measure = auc, interaction = FALSE)
```

As we can see with the above output:
The information gain and gain ratio show a score of zero or a low score for Pregnancies.
generateFeatureImportanceData shows a score of zero for Pregnancies when looking at the TPR and AUC as a performance measure.
Looking at all the evidence, Pregnancies will be the only variable I discard. The other variables still show predictive capabilities across certain criteria.
Seeing as how we are only left with 4 features, there can be a risk of underfitting my model. The other argument for this would be that I do not have many rows of data to deal with in the first place. This is ongoing discussion on what is the right amount of data and features (Curse of Dimensionality).
Looking below I have taken Pregnancies out of our train and test sets and made a new classification task with our new training set.

```{r}
set.seed(1000) 
train <- select(train, -pregnant, -pressure, -triceps) 
test <- select(test, -pregnant, -pressure, -triceps)
list( train = summary(train), test = summary(test) )
```

As we now have new datasets we need to make a new classification task based on the new training set.

```{r}
(dt_task <- makeClassifTask(data=train, target="diabetes"))
```

### Hyperparameter Optimization
When evaluating the models, visualizing the results of hyperparameter tuning can help data scientists narrow down the groupings of hyperparameters that are most important.

Tuning is an important part of modeling. Unlike parameters that derive their value from training, the values of hyperparameters are defined before the learning process begins. These hyperparameters control the behavior of the algorithms and have an impact on the performance of the model. Concerns of hyperparameters, such as trainability, tunability, and robustness, determine the usability of the models.

Below is an example of TensorBoardâ€™s HParams that displays groups of hyperparameters to see which ones are the most important. You can define criteria such as accuracy and dropout rate to determine the performance.

One of the best solutions for this type of task is to use a parallel coordinates plot (Figure 1). Using this type of plot, we can in fact easily compare different variables (eg. features) together in order to discover possible relationships. In the case of Hyperparameters Optimization, this can be used as a simple tool to inspect what combination of parameters can give us the greatest test accuracy. Another possible use of parallel coordinates plots in Data Analysis is to inspect relationships in values between the different features in a data frame.

Now any machine learning algorithm will require us to tune the hyperparameters at our own discretion. Tuning hyperparameters is the process of selecting a value for machine learning parameter with the target of obtaining your desired level of performance.
Tuning a machine learning algorithm in mlr involves the following procedures:
Define a search space.
Define the optimization algorithm (aka tuning method).
Define an evaluation method (i.e. re-sampling strategy and a performance measure).

```{r}
getParamSet("classif.rpart")
```

```{r}
dt_param <- makeParamSet( 
  makeDiscreteParam("minsplit", values=seq(5,10,1)), 
  makeDiscreteParam("minbucket", values=seq(round(5/3,0), round(10/3,0), 1)), 
  makeNumericParam("cp", lower = 0.01, upper = 0.05), 
  makeDiscreteParam("maxcompete", values=6), 
  makeDiscreteParam("usesurrogate", values=0), 
  makeDiscreteParam("maxdepth", values=10) )

ctrl = makeTuneControlGrid()

rdesc = makeResampleDesc("CV", iters = 3L, stratify=TRUE)
```

```{r}
set.seed(1000) 
(dt_tuneparam <- tuneParams(learner=dt_prob, 
                 resampling=rdesc, 
                 measures=list(tpr,auc, fnr, mmce, tnr, setAggregation(tpr, test.sd)), 
                 par.set=dt_param, 
                 control=ctrl, 
                 task=dt_task, 
                 show.info = TRUE) )
```

```{r}
data = generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)
plotHyperParsEffect(data, x = "maxdepth", y = "auc.test.mean", partial.dep.learn = makeLearner("regr.gbm"))

plotHyperParsEffect(data, x = "C", y = "sigma", z = "mmce.test.mean",
  plot.type = "heatmap", interpolate = "regr.earth")
```

```{r}
list( `Optimal HyperParameters` = dt_tuneparam$x, 
      `Optimal Metrics` = dt_tuneparam$y )
```

Using dt_tuneparam$x we can extract the optimal values and dt_tuneparam$y gives us the corresponding performance measures.
setHyperPars will tune the learner with its optimal values.

```{r}
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)

set.seed(1000) 
dtree_train <- train(learner=dtree, task=dt_task) 
getLearnerModel(dtree_train)
```

- As a quick approach, we could plot heatmaps with the possible pairs of different parameters to see the areas where the maximum R2 is achieved in the test and the train sets. This can be done in a couple of lines:

### Decision Trees

Decision Trees are one of the most easily explainable types of Machine Learning model. Thanks to their basilar structure, it is easily possible to examine how the algorithm decides to make its decision by looking at the conditions on the different branches of the tree. Additionally, Decision Trees can also be used as a Feature Selection technique, considering that the algorithm puts at the top levels of the tree the features which think are most valuable for our desired classification/regression task. In this way, the features at the bottom of the tree could be discarded since carrying less information.

```{r}
library(rpart.plot)
rpart.plot(dtree_train$learner.model, roundint=FALSE, varlen=3, type = 3, clip.right.labs = FALSE, yesno = 2)
```

```{r}
rpart.rules(dtree_train$learner.model, roundint = FALSE)
```

### Prediction

```{r}
set.seed(1000) 
(dtree_predict <- predict(dtree_train, newdata = test))
dtree_predict %>% calculateROCMeasures()

model_performance <- performance(dtree_predict, measures = list(tpr,auc,mmce, acc,tnr)) %>% 
  as.data.frame(row.names = c("True Positive","Area Under Curve", "Mean Misclassification Error","Accuracy","True Negative")) 

model_performance
```

```{r}
(dtree_threshold <- generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc, mmce,tnr)) %>% plotThreshVsPerf() + geom_point() )
```

My personal goal for this model will be to obtain an acceptable and satisfactory True Positive Rate and True Negative Rate. Since the AUC remains the same across all thresholds we need not concern ourselves with it. By changing the threshold I am deliberately creating a biased model but this is a normal machine learning problem. The Bias-Variance Tradeoff is so common and we need to learn to navigate throught it. It is a whole other topic and anyone doing machine learning will need some knowledge of it.
Below you will see 3 different thresholds:
The maximum threshold in which our TPR is below 100%.
The minimum threshold in which our TPR is above 80%.
The average of the two thresholds.
The maximum threshold in which our TNR is above 70%.

```{r}
list( 
`TPR Threshold for 100%` = tpr_threshold100 <- dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[ dtree_threshold$data$measure=="True positive rate"]<1)], 
`TPR Threshold for 80%` = tpr_threshold80 <- dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[ dtree_threshold$data$measure=="True positive rate"]>0.80)], 
`Average Threshold` = avg_threshold <- mean(c(tpr_threshold100,tpr_threshold80)), 
`TNR Threshold for 80%` = tnr_threshold80 <- dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[ dtree_threshold$data$measure=="True negative rate"]>0.70)] )
```

Using avg_threhsold to predict on our model one more time we can get the following performance metrics. However looking at the thresholds from the plot and the ones I defined above, our True Negative Rate is going to take a big hit.

```{r}
DecisionTree <- dtree_predict %>% setThreshold(avg_threshold) 
(dt_performance <- DecisionTree %>% performance(measures = list(tpr,auc, mmce,tnr)) )
(dt_cm <- DecisionTree %>% calculateROCMeasures() )
```

The Accuracy has reduced to 66 %. This is another consequence of changing the threshold. This is not a cause for concern because our model does what I intended for it to do â€” Have a high True Positive Rate. Accuracy is not an adequate measure of model performance if we only care about the accurate prediction of a certain outcome. This is the case most of the time but even then you still need to dig deep into the model performance.

```{r}
performance_threshold <- performance(DecisionTree, measures = list(tpr,auc, mmce, acc, tnr)) %>% 
  as.data.frame(row.names = c("True Positive","Area Under Curve", "Mean Misclassification Error","Accuracy","True Negative"))
performance_threshold
```


### Decision Boundaries

Decision Boundaries are one of the easiest approaches to graphically understand how a Machine Learning model is making its predictions. One of the easiest ways to plot decision boundaries in Python is to use Mlxtend. This library, can in fact be used for plotting decision boundaries of either Machine Learning and Deep Learning models. A simple example is shown in Figure 6.
One of the main limitations of plotting decision boundaries is that they can only be easily visualised in two or three dimensions. Due to these limitations, it might be therefore necessary most of the times to reduce the dimensionality of our input features (using some form of feature extraction techniques) before plotting the decision boundary.

Over the next few posts, we will investigate decision boundaries. A decision boundary is a graphical representation of the solution to a classification problem. Decision boundaries can help us to understand what kind of solution might be appropriate for a problem. They can also help us to understand the how various machine learning classifiers arrive at a solution.

In this post, we will look at a problemâ€™s optimal decision boundary, which we can find when we know exactly how our data was generated. The optimal decision boundary represents the â€œbestâ€ solution possible for that problem. Consequently, by looking at the complexity of this boundary and at how much error it produces, we can get an idea of the inherent difficulty of the problem.

Unless we have generated the data ourselves, we wonâ€™t usually be able to find the optimal boundary. Instead, we approximate it using a classifier. A good machine learning classifier tries to approximate the optimal boundary for a problem as closely as possible.

A classification problem asks: given some observations of a thing, what is the best way to assign that thing to a class based on some of its features? For instance, we might want to predict whether a person will like a movie or not based on some data we have about them, the â€œfeaturesâ€ of that person.

A solution to the classification problem is a rule that partitions the features and assigns each all the features of a partition to the same class. The â€œboundaryâ€ of this partitioning is the decision boundary of the rule.

It might be that two observations have exactly the same features, but are assigned to different classes. (Two things that look the same in the ways weâ€™ve observed might differ in ways we havenâ€™t observed.)

The boundary that this rule produces is the optimal decision boundary. It is the MAP estimate of the class label, and it is the rule that minimizes classification error under the zero-one loss function. We will look at error and loss more in a future post.

We will consider binary classification problems, meaning, there will only be two possible classes, 0 or 1. For a binary classification problem, the optimal boundary occurs at those points where each class is equally probable:

Decision boundaries are most easily visualized whenever we have continuous features, most especially when we have two continuous features, because then the decision boundary will exist in a plane.

With two continuous features, the feature space will form a plane, and a decision boundary in this feature space is a set of one or more curves that divide the plane into distinct regions. Inside of a region, all observations will be assigned to the same class.

As mentioned above, whenever we know exactly how our data was generated, we can produce the optimal decision boundary. Though this wonâ€™t usually be possible in practice, investigating the optimal boundaries produced from simulated data can still help us to understand their properties.

We will look at the optimal boundary for a binary classification problem on a with features on a couple of common distributions: a multivariate normal distribution and a mixture of normal distributions.

In a binary classification problem, whenever the features for each class jointly have a multivariate normal distribution, the optimal decision boundary is relatively simple. We will start our investigation here.

With two features, the feature space is a plane. It can be shown that the optimal decision boundary in this case will either be a line or a conic section (that is, an ellipse, a parabola, or a hyperbola). With higher dimesional feature spaces, the decision boundary will form a hyperplane or a quadric surface.

We will consider classification problems with two classes, ð¶=0,1, and two features, ð‘‹ and ð‘Œ. Each class will be Bernoulli distributed and the features for each class will be distributed normally. Specifically,

Our goal is to produce two kinds of visualizations: one, of a sample from these distributions, and two, the contours of the class-conditional densities for each feature. Weâ€™ll use the mvnfast package to help us with computations on the joint M

```{r}
#remotes::install_github("grantmcdermott/parttree")
library(parsnip)
library(parttree)
set.seed(123) ## For consistent jitter

## Build our tree using parsnip (but with rpart as the model engine)
ti_tree =
  decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification") %>%
  fit(diabetes ~ glucose + age, data = PimaIndiansDiabetes)

## Plot the data and model partitions
PimaIndiansDiabetes %>%
  ggplot(aes(x=glucose, y=age)) +
  geom_jitter(aes(col=diabetes), alpha=0.7) +
  geom_parttree(data = ti_tree, aes(fill=diabetes), alpha = 0.1) +
  theme_minimal()
```

https://michael.hahsler.net/SMU/EMIS7332/R/viz_classifier.html

```{r}
decisionplot <- function(model, data, class = NULL, predict_type = "class",
  resolution = 100, showgrid = TRUE, ...) {

  if(!is.null(class)) cl <- data[,class] else cl <- 1
  data <- data[,1:2]
  k <- length(unique(cl))

  plot(data, col = as.integer(cl)+1L, pch = as.integer(cl)+1L, ...)

  # make grid
  r <- sapply(data, range, na.rm = TRUE)
  xs <- seq(r[1,1], r[2,1], length.out = resolution)
  ys <- seq(r[1,2], r[2,2], length.out = resolution)
  g <- cbind(rep(xs, each=resolution), rep(ys, time = resolution))
  colnames(g) <- colnames(r)
  g <- as.data.frame(g)

  ### guess how to get class labels from predict
  ### (unfortunately not very consistent between models)
  p <- predict(model, g, type = predict_type)
  if(is.list(p)) p <- p$class
  p <- as.factor(p)

  if(showgrid) points(g, col = as.integer(p)+1L, pch = ".")

  z <- matrix(as.integer(p), nrow = resolution, byrow = TRUE)
  contour(xs, ys, z, add = TRUE, drawlabels = FALSE,
    lwd = 2, levels = (1:(k-1))+.5)

  invisible(z)
}
```

```{r}
library(e1071)
model <- naiveBayes(diabetes ~ ., data=PimaIndiansDiabetes)
decisionplot(model, PimaIndiansDiabetes, class = "diabetes", main = "naive Bayes")
```

### ANNs

Another technique which can be quite useful when creating new neural network architectures is visualising their structure. 

Li et al, Visualizing the Loss Landscape
of Neural Nets, 2018

http://yosinski.com/deepvis

http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture13.pdf

https://projector.tensorflow.org/

![https://shirinsplayground.netlify.app/2020/09/keras_funct_api/](https://shirinsplayground.netlify.com/img/plot_model_4.png)
https://shirinsplayground.netlify.app/2020/10/keras_workshop_user20/

![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/hist.png)
![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/percentage_pred.png)
![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/percentage_pred_cor.png)

### Learning rates

### Graphical representation of a model in TensorBoard

With the graph visualizer, users can explore different layers of model abstraction, zooming in and out of any part of the schema. Another important benefit of TensorBoard visualization is that nodes of the same types and similar structures are painted with the same colors. Users can also look at coloring by device (CPU, GPU, or a combination of both), highlight a specific node with the â€œtrace inputsâ€ feature, and visualize one or several charts at a time.

This visualization approach makes TensorBoard a popular tool for model performance evaluation, especially for models of complex structures like deep neural networks.

Grant Reaber notes that TensorBoard makes it easy to monitor model training. Grant and his team also use this tool for custom visualizations.

Illia Polosukhin also chooses TensorBoard. â€œTensorBoard shows metrics during model development and allows for making a decision regarding a model. For instance, itâ€™s very comfortable to monitor how a model performs when tweaking its hyperparameters and choosing the one that performs best,â€ summarizes Illia.

Besides displaying performance metrics, TensorBoard can show users a lot of other information like histograms, audio, text, and image data, distributions, embeddings, and scalars.

### Variational Autoencoders

Variational Autoencoders (VAE) are a type of probabilistic generative model used in order to create a latent representation of some input data (eg. images) able to concisely understand the original data and generate brand new data from it (eg. training a VAE model with different images of car designs, could then enable to model to create brand new imaginative car designs).
Continuing from the example Variational Autoencoder trained using Livelossplot, we can even make our model more interesting by examining how the latent space (Figure 9) varies from one iteration to another (and therefore how much our model improved to distinguish the different classes over time).

### Word Embeddings

Neural Network Embeddings are a class of neural networks designed in order to learn how to convert some form of categorical data into numerical data. Using Embeddings can be considerably advantageous than using other techniques such as One Hot Encoding considering that, while converting the data, they are able to learn about its characteristics and therefore construct a more succinct representation (creating a latent space). Two of the most famous types of pre-trained word embeddings are word2vec and Glove.
As a simple example, we are now going to plot an embed space representing different books authors. First of all, we need to create an train a model on some available data and then access the trained weights of the model embedded layer (in this case called embed) and store them in a data frame. Once this process is done, we then just have to plot the three different coordinates (Figure 11).

In this example, the embedding dimensions of the network have been set directly to 3 in order to then easily create the 3D visualization. Another possible solution could have been to instead use a higher embedding output size and then apply some form of feature extraction technique (eg. t-SNE, PCA, etcâ€¦) in order to visualise the results.
Another interesting technique which can be used to visualise categorical data is Wordclouds (Figure 12). This type of representation, can, for example, be realised by creating a dictionary of book authors names and their respective frequency count in the dataset. Authors which appears more frequently in the dataset will be then represented in the figure with greater font size.

The Unreasonable Effectiveness of Recurrent Neural Networks
Karpathy, 2015 

Seq2Seq-Vis:
Visual Debugging
Tool for Sequenceto- Sequence
Models
Strobelt, 2018

What does a sentence look like in embedding space?

https://arxiv.org/pdf/1611.04558.pdf

### translation

http://seq2seq-vis.io/

### time-series

When working with time-series data, it can be really handy at times to be able to quickly understand on which datapoints our model is performing poorly, in order to try to understand what limitations it might be facing.
One possible approach is to create a summary table with the actual and predicted values and some form of metrics summarising how well/bad a data point has been predicted.


### Explainable AI

Explainable AI is nowadays a growing field of research. Use of AI in decision-making applications (such as employment) has recently caused some concerns both for individuals and authorities. This is because, when working with deep neural networks, it is currently not possible (at least to a full extent) to understand the decision-making process the algorithm performs when having to carry out a predetermined task. Because of this lack of transparency in the decision-making process, perplexities can arise from the public regarding the trustworthiness of the model itself. Therefore, the need for Explainable AI is now becoming the next prefixed evolutionary step in order to prevent the presence of any form of bias in AI models.
During the last few years, different visualization techniques have been introduced in order to make Machine Learning more explainable such as:
Exploring Convolutional Neural Networks Filters and Feature maps.
Graphs Networks.
Bayesian-based models.
Causal Reasoning applied to Machine Learning.
Local/Global surrogate models.
Introduction of Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Values.
If you are interested in finding out more about how to make Machine Learning models more explainable, two of the most interesting libraries currently available in Python in order to apply Explainable AI in Deep Learning are Captum by Pytorch and XAI.
As this research area is in constant improvement, I will aim to cover all these different topics (and more) in a future article dedicated to just Explainable AI.

https://shirinsplayground.netlify.app/2018/12/customer_churn_code/

### Image classifiers are effective in practice
Exactly what they're doing is somewhat mysterious
- And their failures (e.g. adversarial examples) add to mystery
But: Way easier to inspect whatâ€™s going on in artificial classifiers than in human
classifiers ;-)
Since these are visual systems, it's natural to use visualization to inspect them
- What features are these networks really using?
- Do individual units have meaning?
- What roles are played by different layers?
- How are high-level concepts built from low-level ones?

Saliency maps
(a.k.a. "Sensitivity maps")
Idea: consider sensitivity of class to each pixel
i.e. grad(f), where f is function from pixels to class score.
Many ways to extend basic idea!
- Layer-wise relevance propagation (Binder et al.)
- Integrated gradients (Sundararajan et al.)
- Guided backprop (Springenberg et al.)
- etc.
Yet interpretation is slippery (Adebayo et al., Kindermans et al.)
- Tend to be visually noisy. Are these sometimes Rorschach tests?
- Are some of these methods essentially edge detectors?

Visualizing and Understanding Convolutional Networks
Zeiler & Fergus, 2013

The Building Blocks of
Interpretability
Olah, Satyanarayan, Johnson, Carter,
Schubert, Ye, Mordvintsev


Lesson
If you see something interesting in
high-dimensional spaceâ€¦
compare to a random baseline!

playground.tensorflow.org

Distill.pub
Editors: Carter, Olah, Satyanarayan

research.google.com/bigpicture/attacking-discrimination-in-ml

Google Creative Lab
https://quickdraw.withgoogle.com/

https://poloclub.github.io/ganlab/

http://lstm.seas.harvard.edu/


Before popular data visualization tools for machine learning were developed, the machine learning process was much more abstract. Historically, ggplot2 in R provided much-needed visualization tools for exploratory data analysis. But today, with the suite of data visualizations that are available in Python, such as seaborn, scikit-learn, and matplotlib, exploratory data analysis that forms the initial part of the machine learning process can be done much more efficiently. At the same time, with TensorFlow, model-building and model-tuning processes become a lot more intuitive. Rather than spending time on scrutinizing values, with the assistance of both 2-dimensional and interactive data visualizations, data scientists can pay more attention to the big picture of the data at each level of the machine learning process to focus more on the meaning of the data, the model design, and the model performance.

Data visualization can power model creation and model tuning
With the advancement of data visualization techniques, model creation and model tuning do not have to be abstract processes. TensorFlow allows you to follow the model-creation process with data visualization at each step, and when building a TensorFlow model, you can visualize the modelâ€™s structure and follow the data to see if the model fits your design.

Below is an example of the conceptual graph of a Keras model. The data flows from the bottom to the top. The graph is a representation of the definition of the model.



---

```{r}
devtools::session_info()
```


