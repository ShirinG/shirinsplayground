---
title: "Update to The Good, the Bad and the Ugly: how to visualize Machine Learning data"
draft: true
author: Dr. Shirin Elsinghorst
date: '2021-04-28'
categories: ["R"]
tags: ["R", "ggplot2"]
thumbnailImagePosition: left
thumbnailImage: post/2020-10-20_goodbadugly_files/figure-html/unnamed-chunk-29-1.png
metaAlignment: center
coverMeta: out
slug: goodbadugly_ml
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Below you'll find the complete code used to create the **ggplot2** graphs in my talk **The Good, the Bad and the Ugly: how to visualize Machine Learning data** at this year's Minds Mastering machines conference. You can find the German [slides here](https://docs.google.com/presentation/d/e/2PACX-1vR4pD2EmW9Gzxr1Q3qwgjEYkU64o2-ThlX1mXqfNQ2EKteVUVt6Qg2ImEKKi9XLv-Iutb3lD8esLyU7/pub?start=false&loop=false&delayms=3000):

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vR4pD2EmW9Gzxr1Q3qwgjEYkU64o2-ThlX1mXqfNQ2EKteVUVt6Qg2ImEKKi9XLv-Iutb3lD8esLyU7/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

You can find [Part 1: **The Good, the Bad and the Ugly: how (not) to visualize data** here](https://shirinsplayground.netlify.app/2020/10/goodbadugly/).

---

If you have questions or would like to talk about this article (or something else data-related), you can now [book 15-minute timeslots](https://shirinsplayground.netlify.app/page/bookme/) with me (it's free - one slot available per weekday): 

<img src="https://www.appointletcdn.com/loader/buttons/F62459.png" data-appointlet-organization="shirin-elsinghorst" data-appointlet-service="357892"><script src="https://www.appointletcdn.com/loader/loader.min.js" async="" defer=""></script>

*If you have been enjoying my content and would like to help me be able to create more, please consider sending me a donation at <button>[paypal.me](https://paypal.me/ShirinGlander)</button>. Thank you!* :-)

---

## Libraries

```{r libraries}
library(tidyverse)
library(mlbench)
library(ggfortify)
library(GGally)
library(scagnostics)
library(mlr) 
```

## Dataset

Pima Indians Diabetes dataset from [*mlbench* package](http://search.r-project.org/library/mlbench/html/PimaIndiansDiabetes.html).

```{r}
data(PimaIndiansDiabetes)
PimaIndiansDiabetes %>%
  head()
```

## Colors

- set [colorblind-friendly palettes](https://jfly.uni-koeln.de/color/)

```{r}
# The palette with grey:
cbp1 <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r}
ggplot <- function(...) ggplot2::ggplot(...) + 
  scale_color_manual(values = cbp1) +
  scale_fill_manual(values = cbp1) + # note: needs to be overridden when using continuous color scales
  theme_bw()
```

## Visualizing Machine Learning models

Visualizing different steps of the machine learning pipeline can help us

- explore the data (EDA),
- understand the data (and identify potential problems),
- pre-process the data in a suitable way for optimal model performance,
- supervise the learning process,
- optimize modeling,
- interpret the model and
- compare and evaluate model predictions.

Visualization also greatly simplifies communication of our model and results to decision-makers or the public.

>Before popular data visualization tools for machine learning were developed, the machine learning process was much more abstract. Historically, ggplot2 in R provided much-needed visualization tools for exploratory data analysis. But today, with the suite of data visualizations that are available in Python, such as seaborn, scikit-learn, and matplotlib, exploratory data analysis that forms the initial part of the machine learning process can be done much more efficiently. At the same time, with TensorFlow, model-building and model-tuning processes become a lot more intuitive. Rather than spending time on scrutinizing values, with the assistance of both 2-dimensional and interactive data visualizations, data scientists can pay more attention to the big picture of the data at each level of the machine learning process to focus more on the meaning of the data, the model design, and the model performance.

>Data visualization can power model creation and model tuning
With the advancement of data visualization techniques, model creation and model tuning do not have to be abstract processes. TensorFlow allows you to follow the model-creation process with data visualization at each step, and when building a TensorFlow model, you can visualize the model’s structure and follow the data to see if the model fits your design.

>Below is an example of the conceptual graph of a Keras model. The data flows from the bottom to the top. The graph is a representation of the definition of the model.

### Exploratory Data Analysis

Exploratory Data Analysis (EDA) is the backbone of data analysis, including those that result in a machine learning model. EDA helps us to understand the data we are working with and put it into context, so that we are able to ask the right questions (or to put our questions into the right frame). It also helps us take appropriate measures for cleaning, normalization/transformation, dealing with missing values, feature preparation and engineering, etc. Particularly if our machine learning model is trained on a limited dataset (but not only then!), appropriate data preparation can vastly improve the machine learning process: models will often train faster and achieve higher accuracy.

An essential part of EDA is data visualization. 

Typically, we want to start by exploring potential sources of errors in our data, like

- **wrong/useless data types** (sometimes data types are automatically set in a way that is not useful for our analysis, like *factors* versus *strings*, or wrong/strange entries in an otherwise numeric column will make it categorical)
- **missing values** (a collection of ways to visualize missingness can be found [here](https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html)),
- **outliers** (for example by plotting a box-plot of continuous variables)

Depending on the number of features/variables we have, it makes sense to look at them all individually and in correlation with each other. Depending on whether we have a categorical or continuous variable, we might be interested in properties that are shown by 

- **histograms** (frequency distribution of binned continuous variables),
- **density distribution** (normalized distribution of continuous variables) or 
- **bar-plots** (shows counts of categorical variables).

If our target variable is categorical, we will want to look at potential imbalances between the classes. Class imbalance will strongly affect the machine learning modeling process and will require us to consider up-/downsampling or similar techniques before we train a model.

**Correlation analysis** can show us, for example

- how our **target/dependent variable correlates with the remaining features** (often, just by looking at the correlation, we can identify one ore more feature that will have a strong impact on predicting the target because they are strongly correlated) or
- whether some of the **independent variables/features correlate with each other** (**multicolinearity**; we might want to consider removing strongly correlated features, so that they won't contribute the "same" information multiple times to the model and thus lead to overfitting).

Additional methods can be used to visualize groups of related features. These methods are often especially useful if we have a large dataset with a large feature set (highly dimensional data). Some of these methods for visualizing groups of related features and/or for comparing multiple variables and visualizing their relationships are:

- **Dimensionality reduction**:
  - *Principal Component Analysis* (PCA, linear, shows as much variation in data as possible)
  - *Multidimensional scaling* (MDS, non-linear)
  - *Sammon mapping* (non-linear)
  - *T-Distributed Stochastic Neighbor Embedding* ([t-SNE](https://cran.r-project.org/web/packages/tsne/tsne.pdf), non-linear)
  - *Uniform Manifold Approximation and Projection* ([UMAP](https://cran.r-project.org/web/packages/umap/vignettes/umap.html), non-linear, faster than T-SNE, often captures global variation better than T-SNE and PCA)
  - *Isometric Feature Mapping Ordination* ([Isomap](https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/isomap))
- [Parallel coordinate plots](https://towardsdatascience.com/parallel-coordinates-plots-6fcfa066dcb3)
- [scagnostics](https://cran.r-project.org/web/packages/scagnostics/index.html)

```{r}
# in our dataset,
# continuous variables are
PimaIndiansDiabetes %>%
  dplyr::select(where(is.numeric)) %>%
  head()

# 'diabetes' is the only categorical variable is also our target or dependent variable
PimaIndiansDiabetes %>%
  dplyr::select(!where(is.numeric)) %>%
  head()
```

```{r}
# bar plot of target
PimaIndiansDiabetes %>%
  ggplot(aes(x = diabetes, fill = diabetes)) +
    geom_bar(alpha = 0.8) +
    theme(legend.position = "none") +
    labs(x = "Diabetes outcome", 
         y = "count",
        title = "Barplot of categorical features", 
        caption = "Source: Pima Indians Diabetes Database")
```

```{r}
# boxplot of continuous features
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_boxplot(alpha = 0.8) +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank())
```

```{r}
# histogram of features
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_histogram(alpha = 0.8) +
    labs(x = "value of feature in facet", 
         y = "count",
         fill = "Diabetes",
        title = "Histogram of features", 
        caption = "Source: Pima Indians Diabetes Database")
```

```{r}
# density plot of of features
PimaIndiansDiabetes %>%
  gather("key", "value", pregnant:age) %>%
  ggplot(aes(x = value, fill = diabetes)) +
    facet_wrap(vars(key), ncol = 3, scales = "free") +
    geom_density(alpha = 0.8) +
    labs(x = "value of feature in facet", 
         y = "density",
         fill = "Diabetes",
        title = "Density of continuous features", 
        caption = "Source: Pima Indians Diabetes Database")
```

```{r}
# correlation plot of features
mat <- PimaIndiansDiabetes %>%
  dplyr::select(where(is.numeric))

cormat <- round(cor(mat), 2)

cormat <- cormat %>%
  as_data_frame() %>%
  mutate(x = colnames(mat)) %>%
  gather(key = "y", value = "value", pregnant:age)

cormat %>%
    remove_missing() %>%
    arrange(x, y) %>%
    ggplot(aes(x = x, y = y, fill = value)) + 
    geom_tile() +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
     midpoint = 0, limit = c(-1,1), space = "Lab", 
     name = "Pearson\nCorrelation") +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
    coord_fixed() +
    labs(x = "feature", 
         y = "feature",
        title = "Correlation between features", 
        caption = "Source: Pima Indians Diabetes Database")
```
```{r fig.width=5}
# scatterplot matrix
ggpairs(PimaIndiansDiabetes, 
        columns = c(1:8),
        alpha = 0.7) +
    labs(x = "feature", 
         y = "feature",
        title = "Scatterplot matrix", 
        caption = "Source: Pima Indians Diabetes Database")
```

```{r}
# PCA
prep <- PimaIndiansDiabetes %>%
  dplyr::select(where(is.numeric))

pca <- prep %>%
  prcomp(scale. = TRUE)

autoplot(pca, 
                data = PimaIndiansDiabetes, 
                colour = 'diabetes',
                shape = 'diabetes',
                loadings = TRUE, 
                loadings.colour = 'blue',
                loadings.label = TRUE, 
                loadings.label.size = 3) +
      scale_color_manual(values = cbp1) +
  scale_fill_manual(values = cbp1) +
  theme_bw() +
    labs(title = "Principal Component Analysis (PCA)", 
        caption = "Source: Pima Indians Diabetes Database")
```

```{r}
# MDS
d <- dist(prep) # euclidean distances between the rows
fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit$points %>%
  head()
```

```{r}
# Sammon mapping
library(MASS)
sam <- sammon(dist(prep))
sam$points %>%
  head()
```

```{r}
# parallel coordinate plots
ggparcoord(data = PimaIndiansDiabetes, 
           columns = c(1:8), 
           groupColumn = 9,
           scale = "robust",
           order = "skewness",
           alpha = 0.7)
```

```{r}
# scagnostics
scagnostics_dataset <- scagnostics(PimaIndiansDiabetes)

# scagnostics grid
scagnostics_grid_dataset <- scagnosticsGrid(scagnostics_dataset)

# outliers
scagnostics_o_dataset <- scagnosticsOutliers(scagnostics_dataset)
scagnostics_o_dataset[scagnostics_o_dataset]
outlier <- scagnostics_grid_dataset[scagnostics_o_dataset,]

# scagnostics exemplars
scagnostics_ex_dataset <- scagnosticsExemplars(scagnostics_dataset)
scagnostics_ex_dataset[scagnostics_ex_dataset]
exemplars <- scagnostics_grid_dataset[scagnostics_ex_dataset,]
```

### Training a machine learning model

(using `mlr` package)

- create training and test set

```{r}
set.seed(1000) 

train_index <- sample(1:nrow(PimaIndiansDiabetes), 0.8 * nrow(PimaIndiansDiabetes)) 
test_index <- setdiff(1:nrow(PimaIndiansDiabetes), train_index) 

train <- PimaIndiansDiabetes[train_index,] 
test <- PimaIndiansDiabetes[test_index,]

list( train = summary(train), test = summary(test) )
```

- create classification task and learner

```{r}
listLearners()
```

```{r}
(dt_task <- makeClassifTask(data = train, target = "diabetes"))
(dt_prob <- makeLearner('classif.gbm', predict.type = "prob"))
```

### Feature Selection
In order to select which features provide the best chance to predict Positive, the generateFilterValuesData gives us a score for each feature. This can then be plotted with PlotFilterValues. The score for each variable is dependent upon which criteria you choose. Here I choose Information Gain, Chi-squared and Gain Ratio as my criteria.

```{r}
library(FSelector)
listFilterMethods()
listFilterEnsembleMethods()
```

```{r}
generateFilterValuesData(dt_task, method = "FSelector_information.gain") %>% 
  plotFilterValues() +
  theme_bw() +
    labs(x = "feature",
         y = "information gain",
         title = "Information gain of features in GBM",
         caption = "Source: Pima Indians Diabetes Database")
```

Estimate how important individual features or groups of features are by contrasting prediction performances. 

The generateFeatureImportanceData function also works in a similar fashion. Except it will show us the importance of each feature according to a given performance criteria. I have chosen True Positive Rate and Area Under the Curve.

```{r}
feat_imp_tpr <- generateFeatureImportanceData(task = dt_task, 
                              learner = dt_prob,
                              measure = tpr, 
                              interaction = FALSE)

feat_imp_tpr$res %>%
  gather() %>%
  ggplot(aes(x = reorder(key, value), y = value)) +
    geom_bar(stat = "identity") +
    labs(x = "feature",
         title = "True positive rate of features in GBM",
         subtitle = "calculated with permutation importance",
         caption = "Source: Pima Indians Diabetes Database")
```

```{r}
feat_imp_auc <- generateFeatureImportanceData(task = dt_task, 
                              learner = dt_prob,
                              measure = auc, 
                              interaction = FALSE)

feat_imp_auc$res %>%
  gather() %>%
  ggplot(aes(x = reorder(key, value), y = value)) +
    geom_bar(stat = "identity") +
    labs(x = "feature",
         title = "Area under the curve of features in GBM",
         subtitle = "calculated with permutation importance",
         caption = "Source: Pima Indians Diabetes Database")
```

As we can see with the above output:
The information gain and gain ratio show a score of zero or a low score for Pregnancies.
generateFeatureImportanceData shows a score of zero for Pregnancies when looking at the TPR and AUC as a performance measure.
Looking at all the evidence, Pregnancies will be the only variable I discard. The other variables still show predictive capabilities across certain criteria.
Seeing as how we are only left with 4 features, there can be a risk of underfitting my model. The other argument for this would be that I do not have many rows of data to deal with in the first place. This is ongoing discussion on what is the right amount of data and features (Curse of Dimensionality).
Looking below I have taken Pregnancies out of our train and test sets and made a new classification task with our new training set.

```{r}
set.seed(1000) 
train <- dplyr::select(train, -pedigree, -pressure, -triceps) 
test <- dplyr::select(test, -pedigree, -pressure, -triceps)
list( train = summary(train), test = summary(test) )
```

As we now have new datasets we need to make a new classification task based on the new training set.

```{r}
(dt_task <- makeClassifTask(data = train, target = "diabetes"))
```

### Hyperparameter Optimization

When evaluating the models, visualizing the results of hyperparameter tuning can help data scientists narrow down the groupings of hyperparameters that are most important.

Tuning is an important part of modeling. Unlike parameters that derive their value from training, the values of hyperparameters are defined before the learning process begins. These hyperparameters control the behavior of the algorithms and have an impact on the performance of the model. Concerns of hyperparameters, such as trainability, tunability, and robustness, determine the usability of the models.

Below is an example of TensorBoard’s HParams that displays groups of hyperparameters to see which ones are the most important. You can define criteria such as accuracy and dropout rate to determine the performance.

One of the best solutions for this type of task is to use a parallel coordinates plot (Figure 1). Using this type of plot, we can in fact easily compare different variables (eg. features) together in order to discover possible relationships. In the case of Hyperparameters Optimization, this can be used as a simple tool to inspect what combination of parameters can give us the greatest test accuracy. Another possible use of parallel coordinates plots in Data Analysis is to inspect relationships in values between the different features in a data frame.

Now any machine learning algorithm will require us to tune the hyperparameters at our own discretion. Tuning hyperparameters is the process of selecting a value for machine learning parameter with the target of obtaining your desired level of performance.
Tuning a machine learning algorithm in mlr involves the following procedures:
Define a search space.
Define the optimization algorithm (aka tuning method).
Define an evaluation method (i.e. re-sampling strategy and a performance measure).

```{r}
getParamSet("classif.gbm")
```

```{r}
dt_param <- makeParamSet( 
  makeIntegerParam("n.trees", lower = 20, upper = 150),
  makeNumericParam("shrinkage", lower = 0.01, upper = 0.1))

ctrl = makeTuneControlGrid()

rdesc = makeResampleDesc("CV", 
                         iters = 3L, 
                         stratify = TRUE)
```

```{r}
set.seed(1000) 
(dt_tuneparam <- tuneParams(learner = dt_prob, 
                             resampling = rdesc, 
                             measures = list(tpr,auc, fnr, mmce, tnr, setAggregation(tpr, test.sd)), 
                             par.set = dt_param, 
                             control = ctrl, 
                             task = dt_task, 
                             show.info = TRUE))
```

```{r}
data = generateHyperParsEffectData(dt_tuneparam, 
                                   partial.dep = TRUE)

plotHyperParsEffect(data, x = "n.trees", y = "tpr.test.mean", partial.dep.learn = makeLearner("regr.gbm"))
plotHyperParsEffect(data, x = "shrinkage", y = "tpr.test.mean", partial.dep.learn = makeLearner("regr.gbm"))
```

```{r}
plotHyperParsEffect(data, 
                    x = "n.trees", 
                    y = "shrinkage",
                    z = "tpr.test.mean", 
                    plot.type = "heatmap",
                    partial.dep.learn = makeLearner("regr.gbm")) +
  theme_bw() +
    labs(title = "Hyperparameter effects data",
         subtitle = "of GBM model with reduced feature set",
         caption = "Source: Pima Indians Diabetes Database")
```

```{r}
list( `Optimal HyperParameters` = dt_tuneparam$x, 
      `Optimal Metrics` = dt_tuneparam$y )
```

Using dt_tuneparam$x we can extract the optimal values and dt_tuneparam$y gives us the corresponding performance measures.
setHyperPars will tune the learner with its optimal values.

```{r}
gbm_final <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)

set.seed(1000) 
gbm_final_train <- train(learner = gbm_final, task = dt_task) 
getLearnerModel(gbm_final_train)
```

- As a quick approach, we could plot heatmaps with the possible pairs of different parameters to see the areas where the maximum R2 is achieved in the test and the train sets. This can be done in a couple of lines:

### Decision Trees

Decision Trees are one of the most easily explainable types of Machine Learning model. Thanks to their basilar structure, it is easily possible to examine how the algorithm decides to make its decision by looking at the conditions on the different branches of the tree. Additionally, Decision Trees can also be used as a Feature Selection technique, considering that the algorithm puts at the top levels of the tree the features which think are most valuable for our desired classification/regression task. In this way, the features at the bottom of the tree could be discarded since carrying less information.

- Recursive Partitioning ([`rpart`](https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf) & [`rpart.plot`](http://www.milbo.org/rpart-plot/prp.pdf))

```{r}
library(rpart)
library(rpart.plot)

rpart_tree <- rpart(diabetes ~ .,
                    data = train,
                    method = "class")
```

```{r}
rpart.plot(rpart_tree, 
           roundint=FALSE, 
           type = 3, 
           clip.right.labs = FALSE)
```

```{r}
rpart.rules(rpart_tree, roundint = FALSE)
```

### Prediction

```{r}
set.seed(1000) 
(gbm_final_predict <- predict(gbm_final_train, newdata = test))
gbm_final_predict %>% calculateROCMeasures()
```

```{r}
model_performance <- performance(gbm_final_predict, 
                                 measures = list(tpr, auc, mmce, acc, tnr)) %>% 
  as.data.frame(row.names = c("True Positive Rate","Area Under Curve", "Mean Misclassification Error","Accuracy","True Negative Rate")) 

model_performance
```

```{r}
gbm_final_threshold <- generateThreshVsPerfData(gbm_final_predict, 
                                                 measures = list(tpr, auc, mmce, tnr))
```

```{r}
gbm_final_threshold %>% 
   plotROCCurves() + 
   geom_point() +
    theme_bw() +
    labs(title = "ROC curve from predictions",
         subtitle = "of GBM model with reduced feature set",
         caption = "Source: Pima Indians Diabetes Database")
```

```{r}
gbm_final_threshold %>% 
   plotThreshVsPerf() + 
   geom_point() +
    theme_bw() +
    labs(title = "Threshold vs. performance",
         subtitle = "for 2-class classification of GBM model with reduced feature set",
         caption = "Source: Pima Indians Diabetes Database")
```

```{r}
gbm_final_threshold$data
```

```{r}
gbm_final_thr <- gbm_final_predict %>% 
  setThreshold(0.59595960) 

(dt_performance <- gbm_final_thr %>% performance(measures = list(tpr, auc, mmce, tnr)) )
(dt_cm <- gbm_final_thr %>% calculateROCMeasures() )
```

```{r}
performance_threshold <- performance(gbm_final_thr, measures = list(tpr, auc, mmce, acc, tnr)) %>% 
  as.data.frame(row.names = c("True Positive Rate", "Area Under Curve", "Mean Misclassification Error", "Accuracy", "True Negative Rate"))

performance_threshold
```

### Decision Boundaries

Decision Boundaries are one of the easiest approaches to graphically understand how a Machine Learning model is making its predictions. 
One of the main limitations of plotting decision boundaries is that they can only be easily visualised in two or three dimensions. Due to these limitations, it might be therefore necessary most of the times to reduce the dimensionality of our input features (using some form of feature extraction techniques) before plotting the decision boundary.

A decision boundary is a graphical representation of the solution to a classification problem. Decision boundaries can help us to understand what kind of solution might be appropriate for a problem. They can also help us to understand the how various machine learning classifiers arrive at a solution.

The optimal decision boundary represents the “best” solution possible for that problem. Consequently, by looking at the complexity of this boundary and at how much error it produces, we can get an idea of the inherent difficulty of the problem.

Unless we have generated the data ourselves, we won’t usually be able to find the optimal boundary. Instead, we approximate it using a classifier. A good machine learning classifier tries to approximate the optimal boundary for a problem as closely as possible.

A solution to the classification problem is a rule that partitions the features and assigns each all the features of a partition to the same class. The “boundary” of this partitioning is the decision boundary of the rule.

It might be that two observations have exactly the same features, but are assigned to different classes. (Two things that look the same in the ways we’ve observed might differ in ways we haven’t observed.)

The boundary that this rule produces is the optimal decision boundary. It is the MAP estimate of the class label, and it is the rule that minimizes classification error under the zero-one loss function. 

We will consider binary classification problems, meaning, there will only be two possible classes.

Decision boundaries are most easily visualized whenever we have continuous features, most especially when we have two continuous features, because then the decision boundary will exist in a plane.

With two continuous features, the feature space will form a plane, and a decision boundary in this feature space is a set of one or more curves that divide the plane into distinct regions. Inside of a region, all observations will be assigned to the same class.

As mentioned above, whenever we know exactly how our data was generated, we can produce the optimal decision boundary. Though this won’t usually be possible in practice, investigating the optimal boundaries produced from simulated data can still help us to understand their properties.

With two features, the feature space is a plane. It can be shown that the optimal decision boundary in this case will either be a line or a conic section (that is, an ellipse, a parabola, or a hyperbola). With higher dimesional feature spaces, the decision boundary will form a hyperplane or a quadric surface.

```{r}
#remotes::install_github("grantmcdermott/parttree")
library(parsnip)
library(parttree)
set.seed(123) ## For consistent jitter

## Build our tree using parsnip (but with rpart as the model engine)
ti_tree =
  decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification") %>%
  fit(diabetes ~ glucose + mass, data = PimaIndiansDiabetes)

## Plot the data and model partitions
PimaIndiansDiabetes %>%
  ggplot(aes(x = glucose, y = mass)) +
  geom_jitter(aes(col = diabetes), alpha = 0.7) +
  geom_parttree(data = ti_tree, aes(fill = diabetes), alpha = 0.1) +
  theme_bw() +
    labs(title = "Decision boundaries",
         subtitle = "for 2-class classification of RPART model (glucose + mass)",
         caption = "Source: Pima Indians Diabetes Database")
```

### Time-series

When working with time-series data, it can be really handy at times to be able to quickly understand on which datapoints our model is performing poorly, in order to try to understand what limitations it might be facing.
One possible approach is to create a summary table with the actual and predicted values and some form of metrics summarising how well/bad a data point has been predicted.

![https://shiring.github.io/forecasting/2017/06/09/retail_forcasting_part2](https://shiring.github.io/forecasting/2017/06/09/retail_forcasting_part2_files/figure-markdown_github/unnamed-chunk-28-1.png)

![https://shiring.github.io/forecasting/2017/06/13/retail_forcasting_part3](https://shiring.github.io/forecasting/2017/06/13/retail_forcasting_part3_files/figure-markdown_github/unnamed-chunk-12-1.png)

### Artificial Neural Networks (ANNs)

- [playground.tensorflow.org](playground.tensorflow.org)

- [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r)

1. [Visualizing what convnets learn](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/5.4-visualizing-what-convnets-learn.nb.html)
2. [Deep Dreaming](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/8.2-deep-dream.nb.html)
3. [Neural style transfer](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/8.3-neural-style-transfer.nb.html)

- [Li et al, Visualizing the Loss Landscape of Neural Nets, 2018](https://arxiv.org/pdf/1712.09913.pdf)

- [Understanding Neural Networks Through Deep Visualization, Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson](http://yosinski.com/deepvis)

- [Visualizing Data using the Embedding Projector in TensorBoard](https://projector.tensorflow.org/)

- [Visualizing and Understanding Convolutional Networks, Zeiler & Fergus, 2013](https://arxiv.org/pdf/1311.2901.pdf)

- [The Building Blocks of Interpretability, Olah, Satyanarayan, Johnson, Carter, Schubert, Ye, Mordvintsev](https://distill.pub/2018/building-blocks/)

- [Google Creative Lab](https://quickdraw.withgoogle.com/)

- [Play with Generative Adversarial Networks (GANs) in your browser](https://poloclub.github.io/ganlab/)

- [Visual Analysis for Recurrent Neural Networks](http://lstm.seas.harvard.edu/)

- Another technique which can be quite useful when creating new neural network architectures is visualising their structure. 

![https://shirinsplayground.netlify.app/2020/09/keras_funct_api/](https://shirinsplayground.netlify.com/img/plot_model_4.png)
- [Deep Learning with Keras and TensorFlow](https://shirinsplayground.netlify.app/2020/10/keras_workshop_user20/)

![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/hist.png)
![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/percentage_pred.png)
![https://shirinsplayground.netlify.app/2020/09/keras_fruits_update/](https://shirinsplayground.netlify.com/img/percentage_pred_cor.png)

- [Visualize the effectiveness of different learning rates](http://web.cse.ohio-state.edu/~wang.6195/vis-final/index.html) & [Setting the learning rate of your neural network.](https://www.jeremyjordan.me/nn-learning-rate/)

### Graphical representation of a model in TensorBoard

https://www.tensorflow.org/tensorboard

With the graph visualizer, users can explore different layers of model abstraction, zooming in and out of any part of the schema. Another important benefit of TensorBoard visualization is that nodes of the same types and similar structures are painted with the same colors. Users can also look at coloring by device (CPU, GPU, or a combination of both), highlight a specific node with the “trace inputs” feature, and visualize one or several charts at a time.

This visualization approach makes TensorBoard a popular tool for model performance evaluation, especially for models of complex structures like deep neural networks.

Grant Reaber notes that TensorBoard makes it easy to monitor model training. Grant and his team also use this tool for custom visualizations.

Besides displaying performance metrics, TensorBoard can show users a lot of other information like histograms, audio, text, and image data, distributions, embeddings, and scalars.

### Word Embeddings

Neural Network Embeddings are a class of neural networks designed in order to learn how to convert some form of categorical data into numerical data. Using Embeddings can be considerably advantageous than using other techniques such as One Hot Encoding considering that, while converting the data, they are able to learn about its characteristics and therefore construct a more succinct representation (creating a latent space). Two of the most famous types of pre-trained word embeddings are word2vec and Glove.
As a simple example, we are now going to plot an embed space representing different books authors. First of all, we need to create an train a model on some available data and then access the trained weights of the model embedded layer (in this case called embed) and store them in a data frame. Once this process is done, we then just have to plot the three different coordinates (Figure 11).

In this example, the embedding dimensions of the network have been set directly to 3 in order to then easily create the 3D visualization. Another possible solution could have been to instead use a higher embedding output size and then apply some form of feature extraction technique (eg. t-SNE, PCA, etc…) in order to visualise the results.
Another interesting technique which can be used to visualise categorical data is Wordclouds (Figure 12). This type of representation, can, for example, be realised by creating a dictionary of book authors names and their respective frequency count in the dataset. Authors which appears more frequently in the dataset will be then represented in the figure with greater font size.

- [The Unreasonable Effectiveness of Recurrent Neural Networks, Karpathy, 2015](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

- [Seq2Seq-Vis: Visual Debugging Tool for Sequenceto- Sequence Models, Strobelt, 2018](https://arxiv.org/pdf/1804.09299.pdf)

- [Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation](https://arxiv.org/pdf/1611.04558.pdf)

### Explainable AI

Explainable AI is nowadays a growing field of research. Use of AI in decision-making applications (such as employment) has recently caused some concerns both for individuals and authorities. This is because, when working with deep neural networks, it is currently not possible (at least to a full extent) to understand the decision-making process the algorithm performs when having to carry out a predetermined task. Because of this lack of transparency in the decision-making process, perplexities can arise from the public regarding the trustworthiness of the model itself. Therefore, the need for Explainable AI is now becoming the next prefixed evolutionary step in order to prevent the presence of any form of bias in AI models.
During the last few years, different visualization techniques have been introduced in order to make Machine Learning more explainable such as:
Exploring Convolutional Neural Networks Filters and Feature maps.
Graphs Networks.
Bayesian-based models.
Causal Reasoning applied to Machine Learning.
Local/Global surrogate models.
Introduction of Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Values.
If you are interested in finding out more about how to make Machine Learning models more explainable, two of the most interesting libraries currently available in Python in order to apply Explainable AI in Deep Learning are Captum by Pytorch and XAI.
As this research area is in constant improvement, I will aim to cover all these different topics (and more) in a future article dedicated to just Explainable AI.

![https://shirinsplayground.netlify.app/2021/03/update_customer_churn/](https://shirinsplayground.netlify.com/post/2021-03-25_update_customer_churn_files/figure-html/unnamed-chunk-53-1.png)

- [Interpretable Machine Learning, A Guide for Making Black Box Models Explainable. Christoph Molnar](https://christophm.github.io/interpretable-ml-book/)

- [Equality of Opportunity in Supervised Learning](https://arxiv.org/abs/1610.02413)

---

```{r}
devtools::session_info()
```


