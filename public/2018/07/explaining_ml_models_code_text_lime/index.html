

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.27 with theme Tranquilpeak 0.4.1-BETA">
    <title>Explaining Black-Box Machine Learning Models - Code Part 2: Text classification with LIME</title>
    <meta name="author" content="Dr. Shirin Glander">
    <meta name="keywords" content=", R">

    <link rel="icon" href="img/favicon.png">
    

    
    <meta name="description" content="This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:

Explaining supervised classification models built on tabular data using caret and the iml package Explaining image classification models with keras and lime Explaining text classification models with xgboost and lime">
    <meta property="og:description" content="This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:

Explaining supervised classification models built on tabular data using caret and the iml package Explaining image classification models with keras and lime Explaining text classification models with xgboost and lime">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Explaining Black-Box Machine Learning Models - Code Part 2: Text classification with LIME">
    <meta property="og:url" content="/2018/07/explaining_ml_models_code_text_lime/">
    <meta property="og:site_name" content="Shirin&#39;s playgRound">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Shirin&#39;s playgRound">
    <meta name="twitter:description" content="This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:

Explaining supervised classification models built on tabular data using caret and the iml package Explaining image classification models with keras and lime Explaining text classification models with xgboost and lime">
    
      <meta name="twitter:creator" content="@ShirinGlander">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=640">
    

    
      <meta property="og:image" content="https://shiring.github.io/netlify_images/text_explanation_1.png">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-86119417-1', 'auto');
ga('send', 'pageview');
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Shirin&#39;s playgRound</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">Explaining Black-Box Machine Learning Models - Code Part 2: Text classification with LIME</h1>
        <a href="https://blog.feedspot.com/r_programming_blogs/" rel="nofollow" title="R Programming Blogs"><img alt="R Programming Blogs" src="https://blog.feedspot.com/wp-content/uploads/2018/04/r_program_216px.png?x20694"/></a>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Dr. Shirin Glander</h4>
        
          <h5 class="sidebar-profile-bio">Biologist turned Bioinformatician turned Data Scientist</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/about/">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/conferences_podcasts_webinars/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bullhorn"></i>
      
      <span class="sidebar-button-desc">Hear me talk</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://shiring.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">My old R-blog</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/ShirinG">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/shirin-glander-01120881/">
    
      <i class="sidebar-button-icon fa fa-lg fa-linkedin"></i>
      
      <span class="sidebar-button-desc">LinkedIn</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/6623620/shirin-glander">
    
      <i class="sidebar-button-icon fa fa-lg fa-stack-overflow"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/ShirinGlander">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.xing.com/profile/Shirin_Glander">
    
      <i class="sidebar-button-icon fa fa-lg fa-xing"></i>
      
      <span class="sidebar-button-desc">Xing</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.meetup.com/Munster-R-Users-Group">
    
      <i class="sidebar-button-icon fa fa-lg fa-meetup"></i>
      
      <span class="sidebar-button-desc">MünsteR</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-users.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-users</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      Explaining Black-Box Machine Learning Models - Code Part 2: Text classification with LIME
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-07-26T00:00:00Z">
        
  July 26, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/plot_text_explanations/plot_text_explanations.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plot_text_explanations-binding/plot_text_explanations.js"></script>


<p>This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:</p>
<p><br></p>
<ol style="list-style-type: decimal">
<li>Explaining supervised classification models built on tabular data using <code>caret</code> and the <code>iml</code> package</li>
<li>Explaining image classification models with <code>keras</code> and <code>lime</code></li>
<li>Explaining text classification models with <code>xgboost</code> and <code>lime</code></li>
</ol>
<p><br></p>
<ul>
<li>The first part has been published <a href="https://shirinsplayground.netlify.com/2018/07/explaining_ml_models_code_caret_iml/">here</a>.</li>
<li>The second part has been published <a href="https://shirinsplayground.netlify.com/2018/06/keras_fruits_lime/">here</a>.</li>
</ul>
<p>Below, you will find the code for the third part: Text classification with <a href="https://cran.r-project.org/web/packages/lime/index.html">lime</a>.</p>
<pre class="r"><code># data wrangling
library(tidyverse)
library(readr)

# plotting
library(ggthemes)
theme_set(theme_minimal())

# text prep
library(text2vec)

# ml
library(caret)
library(xgboost)

# explanation
library(lime)</code></pre>
<div id="text-classification-models" class="section level2">
<h2>Text classification models</h2>
<p>Here I am using another Kaggle dataset: <a href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews">Women’s e-commerce cloting reviews</a>. The data contains a text review of different items of clothing, as well as some additional information, like rating, division, etc.</p>
<p>In this example, I will use the review title and text in order to classify whether or not the item was liked. I am creating the response variable from the rating: every item rates with 5 stars is considered “liked” (1), the rest as “not liked” (0). I am also combining review title and text.</p>
<pre class="r"><code>clothing_reviews &lt;- read_csv(&quot;/Users/shiringlander/Documents/Github/ix_lime_etc/Womens Clothing E-Commerce Reviews.csv&quot;) %&gt;%
  mutate(Liked = as.factor(ifelse(Rating == 5, 1, 0)),
         text = paste(Title, `Review Text`),
         text = gsub(&quot;NA&quot;, &quot;&quot;, text))</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   X1 = col_integer(),
##   `Clothing ID` = col_integer(),
##   Age = col_integer(),
##   Title = col_character(),
##   `Review Text` = col_character(),
##   Rating = col_integer(),
##   `Recommended IND` = col_integer(),
##   `Positive Feedback Count` = col_integer(),
##   `Division Name` = col_character(),
##   `Department Name` = col_character(),
##   `Class Name` = col_character()
## )</code></pre>
<pre class="r"><code>glimpse(clothing_reviews)</code></pre>
<pre><code>## Observations: 23,486
## Variables: 13
## $ X1                        &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11...
## $ `Clothing ID`             &lt;int&gt; 767, 1080, 1077, 1049, 847, 1080, 85...
## $ Age                       &lt;int&gt; 33, 34, 60, 50, 47, 49, 39, 39, 24, ...
## $ Title                     &lt;chr&gt; NA, NA, &quot;Some major design flaws&quot;, &quot;...
## $ `Review Text`             &lt;chr&gt; &quot;Absolutely wonderful - silky and se...
## $ Rating                    &lt;int&gt; 4, 5, 3, 5, 5, 2, 5, 4, 5, 5, 3, 5, ...
## $ `Recommended IND`         &lt;int&gt; 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, ...
## $ `Positive Feedback Count` &lt;int&gt; 0, 4, 0, 0, 6, 4, 1, 4, 0, 0, 14, 2,...
## $ `Division Name`           &lt;chr&gt; &quot;Initmates&quot;, &quot;General&quot;, &quot;General&quot;, &quot;...
## $ `Department Name`         &lt;chr&gt; &quot;Intimate&quot;, &quot;Dresses&quot;, &quot;Dresses&quot;, &quot;B...
## $ `Class Name`              &lt;chr&gt; &quot;Intimates&quot;, &quot;Dresses&quot;, &quot;Dresses&quot;, &quot;...
## $ Liked                     &lt;fct&gt; 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, ...
## $ text                      &lt;chr&gt; &quot; Absolutely wonderful - silky and s...</code></pre>
<p>Whether an item was liked or not will thus be my response variable or label for classification.</p>
<pre class="r"><code>clothing_reviews %&gt;%
  ggplot(aes(x = Liked, fill = Liked)) +
    geom_bar(alpha = 0.8) +
    scale_fill_tableau(palette = &quot;tableau20&quot;) +
    guides(fill = FALSE)</code></pre>
<p><img src="/post/2018-07-26_explaining_ml_models_code_text_lime_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Let’s split the data into train and test sets:</p>
<pre class="r"><code>set.seed(42)
idx &lt;- createDataPartition(clothing_reviews$Liked, 
                           p = 0.8, 
                           list = FALSE, 
                           times = 1)

clothing_reviews_train &lt;- clothing_reviews[ idx,]
clothing_reviews_test  &lt;- clothing_reviews[-idx,]</code></pre>
</div>
<div id="lets-start-simple" class="section level2">
<h2>Let’s start simple</h2>
<p>The first text model I’m looking at has been built similarly to the example model in the help for <code>lime::interactive_text_explanations()</code>.</p>
<p>First, we need to prepare the data for modeling: we will need to convert the text to a document term matrix (dtm). There are different ways to do this. One is be with the <code>text2vec</code> package.</p>
<blockquote>
<p>“Because of R’s copy-on-modify semantics, it is not easy to iteratively grow a DTM. Thus constructing a DTM, even for a small collections of documents, can be a serious bottleneck for analysts and researchers. It involves reading the whole collection of text documents into RAM and processing it as single vector, which can easily increase memory use by a factor of 2 to 4. The text2vec package solves this problem by providing a better way of constructing a document-term matrix.” <a href="https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html" class="uri">https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html</a></p>
</blockquote>
<p>Alternatives to <code>text2vec</code> would be <code>tm</code> + <code>SnowballC</code> or you could work with the <code>tidytext</code> package.</p>
<p>The <code>itoken()</code> function creates vocabularies (here stemmed words), from which we can create the dtm with the <code>create_dtm()</code> function.</p>
<p>All preprocessing steps, starting from the raw text, need to be wrapped in a function that can then be pasted into the <code>lime::lime()</code> function; this is only necessary if you want to use your model with <code>lime</code>.</p>
<pre class="r"><code>get_matrix &lt;- function(text) {
  it &lt;- itoken(text, progressbar = FALSE)
  create_dtm(it, vectorizer = hash_vectorizer())
}</code></pre>
<p>Now, this preprocessing function can be applied to both training and test data.</p>
<pre class="r"><code>dtm_train &lt;- get_matrix(clothing_reviews_train$text)
str(dtm_train)</code></pre>
<pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots
##   ..@ i       : int [1:889012] 304 764 786 788 793 794 1228 2799 2819 3041 ...
##   ..@ p       : int [1:262145] 0 0 0 0 0 0 0 0 0 0 ...
##   ..@ Dim     : int [1:2] 18789 262144
##   ..@ Dimnames:List of 2
##   .. ..$ : chr [1:18789] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : NULL
##   ..@ x       : num [1:889012] 1 1 2 1 2 1 1 1 1 1 ...
##   ..@ factors : list()</code></pre>
<pre class="r"><code>dtm_test &lt;- get_matrix(clothing_reviews_test$text)
str(dtm_test)</code></pre>
<pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots
##   ..@ i       : int [1:222314] 2793 400 477 622 2818 2997 3000 4500 3524 2496 ...
##   ..@ p       : int [1:262145] 0 0 0 0 0 0 0 0 0 0 ...
##   ..@ Dim     : int [1:2] 4697 262144
##   ..@ Dimnames:List of 2
##   .. ..$ : chr [1:4697] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : NULL
##   ..@ x       : num [1:222314] 1 1 1 1 1 1 1 1 1 1 ...
##   ..@ factors : list()</code></pre>
<p>And we use it to train a model with the <code>xgboost</code> package (just as in the example of the <code>lime</code> package).</p>
<pre class="r"><code>xgb_model &lt;- xgb.train(list(max_depth = 7, 
                            eta = 0.1, 
                            objective = &quot;binary:logistic&quot;,
                            eval_metric = &quot;error&quot;, nthread = 1),
                       xgb.DMatrix(dtm_train, 
                                   label = clothing_reviews_train$Liked == &quot;1&quot;),
                       nrounds = 50)</code></pre>
<p>Let’s try it on the test data and see how it performs:</p>
<pre class="r"><code>pred &lt;- predict(xgb_model, dtm_test)

confusionMatrix(clothing_reviews_test$Liked,
                as.factor(round(pred, digits = 0)))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1370  701
##          1  421 2205
##                                           
##                Accuracy : 0.7611          
##                  95% CI : (0.7487, 0.7733)
##     No Information Rate : 0.6187          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5085          
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
##                                           
##             Sensitivity : 0.7649          
##             Specificity : 0.7588          
##          Pos Pred Value : 0.6615          
##          Neg Pred Value : 0.8397          
##              Prevalence : 0.3813          
##          Detection Rate : 0.2917          
##    Detection Prevalence : 0.4409          
##       Balanced Accuracy : 0.7619          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<p>Okay, not a perfect score but good enough for me - right now, I’m more interested in the explanations of the model’s predictions. For this, we need to run the <code>lime()</code> function and give it</p>
<ul>
<li>the text input that was used to construct the model</li>
<li>the trained model</li>
<li>the preprocessing function</li>
</ul>
<pre class="r"><code>explainer &lt;- lime(clothing_reviews_train$text, 
                  xgb_model, 
                  preprocess = get_matrix)</code></pre>
<p>With this, we could right away call the interactive explainer Shiny app, where we can type any text we want into the field on the left and see the explanation on the right: words that are underlined green support the classification, red words contradict them.</p>
<pre class="r"><code>interactive_text_explanations(explainer)</code></pre>
<div class="figure">
<img src="https://shiring.github.io/netlify_images/text_explanation_2.png" />

</div>
<p>What happens in the background in the app, we can do explicitly by calling the <code>explain()</code> function and give it</p>
<ul>
<li>the test data (here the first four reviews of the test set)</li>
<li>the explainer defined with the <code>lime()</code> function</li>
<li>the number of labels we want to have explanations for (alternatively, you set the label by name)</li>
<li>and the number of features (in this case words) that should be included in the explanations</li>
</ul>
<p>We can plot them either with the <code>plot_text_explanations()</code> function, which gives an output like in the Shiny app or we use the regular <code>plot_features()</code> function.</p>
<pre class="r"><code>explanations &lt;- lime::explain(clothing_reviews_test$text[1:4], explainer, n_labels = 1, n_features = 5)
plot_text_explanations(explanations)</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="plot_text_explanations html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"html":"<div style=\"overflow-y:scroll;font-family:sans-serif;position:absolute;height:100%\"> <p>  <span class='positive_1'>Absolutely<\/span> wonderful - <span class='positive_1'>silky<\/span> <span class='positive_1'>and<\/span> <span class='positive_1'>sexy<\/span> <span class='positive_1'>and<\/span> <span class='positive_5'>comfortable<\/span> <\/br> <sub>Label predicted: 1 (73.17%)<br/>Explainer fit: 1<\/sub> <\/p><br/><p> Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) <span class='positive_2'>but<\/span> i found this to be outrageously small. so small in fact that i could <span class='positive_1'>not<\/span> zip it up! i reordered it in petite medium, which <span class='positive_2'>was<\/span> just ok. overall, the top half <span class='positive_2'>was<\/span> <span class='negative_1'>comfortable<\/span> and fit nicely, <span class='positive_2'>but<\/span> the bottom half had a very tight under layer and several somewhat <span class='positive_2'>cheap<\/span> (net) over layers. imo, a major design flaw <span class='positive_2'>was<\/span> the net over layer sewn directly into the zipper - it c <\/br> <sub>Label predicted: 0 (71.45%)<br/>Explainer fit: 0.84<\/sub> <\/p><br/><p> Flattering shirt This shirt is very <span class='positive_1'>flattering<\/span> to all due to <span class='negative_1'>the<\/span> adjustable front tie. it is <span class='negative_1'>the<\/span> <span class='positive_2'>perfect<\/span> length to wear with leggings and it is sleeveless <span class='positive_1'>so<\/span> it pairs well with any cardigan. <span class='positive_3'>love<\/span> this shirt!!! <\/br> <sub>Label predicted: 1 (84.2%)<br/>Explainer fit: 0.98<\/sub> <\/p><br/><p> <span class='positive_1'>Pretty<\/span> party dress <span class='negative_1'>with<\/span> some issues This is a nice choice for holiday gatherings. i like that the length grazes the knee so it is conservative enough for office related gatherings. the size small fit me well - i am usually a size 2/4 <span class='negative_1'>with<\/span> a small bust. in my opinion it <span class='positive_1'>runs<\/span> small and those <span class='negative_1'>with<\/span> larger busts will definitely have to size up (<span class='positive_3'>but<\/span> then perhaps the waist will be <span class='positive_1'>too<\/span> big). the problem <span class='negative_1'>with<\/span> this dress is the quality. the fabrics are terrible. the delicate netting type fabric on the top layer of skirt got stuck in the zip <\/br> <sub>Label predicted: 0 (56.99%)<br/>Explainer fit: 0.91<\/sub> <\/p> <\/div>"},"evals":[],"jsHooks":[]}</script>
<p><br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br></p>
<pre class="r"><code>plot_features(explanations)</code></pre>
<p><img src="/post/2018-07-26_explaining_ml_models_code_text_lime_files/figure-html/lime_text_plot-1.png" width="576" /></p>
<p>As we can see, our explanations contain a lot of stop-words that don’t really make much sense as features in our model. So…</p>
</div>
<div id="lets-try-a-more-complex-example" class="section level2">
<h2>… let’s try a more complex example</h2>
<p>Okay, our model above works but there are still common words and stop words in our model that LIME picks up on. Ideally, we would want to remove them before modeling and keep only relevant words. This we can accomplish by using additional steps and options in our preprocessing function.</p>
<p>Important to know is that whatever preprocessing we do with our text corpus, train and test data has to have the same features (i.e. words)! If we were to incorporate all the steps shown below into one function and call it separately on train and test data, we would end up with different words in our dtm and the <code>predict()</code> function won’t work any more. In the simple example above, it works <a href="https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html">because we have been using the <code>hash_vectorizer()</code></a>.</p>
<p>Nevertheless, the <code>lime::explain()</code> function expects a preprocessing function that takes a character vector as input.</p>
<p>How do we go about this? First, we will need to create the vocabulary just from the training data. To reduce the number of words to only the most relevant I am performing the following steps:</p>
<ul>
<li>stem all words</li>
<li>remove step-words</li>
<li>prune vocabulary</li>
<li>transform into vector space</li>
</ul>
<pre class="r"><code>stem_tokenizer &lt;- function(x) {
  lapply(word_tokenizer(x), 
         SnowballC::wordStem, 
         language = &quot;en&quot;)
}

stop_words = tm::stopwords(kind = &quot;en&quot;)

# create prunded vocabulary
vocab_train &lt;- itoken(clothing_reviews_train$text, 
                     preprocess_function = tolower, 
                     tokenizer = stem_tokenizer,
                     progressbar = FALSE)
  
v &lt;- create_vocabulary(vocab_train, 
                       stopwords = stop_words)
  
pruned_vocab &lt;- prune_vocabulary(v, 
                                  doc_proportion_max = 0.99, 
                                  doc_proportion_min = 0.01)
  
vectorizer_train &lt;- vocab_vectorizer(pruned_vocab)</code></pre>
<p>This vector space can now be added to the preprocessing function, which we can then apply to both train and test data. Here, I am also transforming the word counts to <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">tfidf</a> values.</p>
<pre class="r"><code># preprocessing function
create_dtm_mat &lt;- function(text, vectorizer = vectorizer_train) {
  
  vocab &lt;- itoken(text, 
               preprocess_function = tolower, 
               tokenizer = stem_tokenizer,
               progressbar = FALSE)
  
  dtm &lt;- create_dtm(vocab, 
             vectorizer = vectorizer)
  
  tfidf = TfIdf$new()
  fit_transform(dtm, tfidf)
}</code></pre>
<pre class="r"><code>dtm_train2 &lt;- create_dtm_mat(clothing_reviews_train$text)
str(dtm_train2)</code></pre>
<pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots
##   ..@ i       : int [1:415770] 26 74 169 294 588 693 703 708 727 759 ...
##   ..@ p       : int [1:506] 0 189 380 574 765 955 1151 1348 1547 1740 ...
##   ..@ Dim     : int [1:2] 18789 505
##   ..@ Dimnames:List of 2
##   .. ..$ : chr [1:18789] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:505] &quot;ad&quot; &quot;sandal&quot; &quot;depend&quot; &quot;often&quot; ...
##   ..@ x       : num [1:415770] 0.177 0.135 0.121 0.17 0.131 ...
##   ..@ factors : list()</code></pre>
<pre class="r"><code>dtm_test2 &lt;- create_dtm_mat(clothing_reviews_test$text)
str(dtm_test2)</code></pre>
<pre><code>## Formal class &#39;dgCMatrix&#39; [package &quot;Matrix&quot;] with 6 slots
##   ..@ i       : int [1:103487] 228 304 360 406 472 518 522 624 732 784 ...
##   ..@ p       : int [1:506] 0 53 113 151 186 216 252 290 323 360 ...
##   ..@ Dim     : int [1:2] 4697 505
##   ..@ Dimnames:List of 2
##   .. ..$ : chr [1:4697] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:505] &quot;ad&quot; &quot;sandal&quot; &quot;depend&quot; &quot;often&quot; ...
##   ..@ x       : num [1:103487] 0.263 0.131 0.135 0.109 0.179 ...
##   ..@ factors : list()</code></pre>
<p>And we will train another gradient boosting model:</p>
<pre class="r"><code>xgb_model2 &lt;- xgb.train(params = list(max_depth = 10, 
                            eta = 0.2, 
                            objective = &quot;binary:logistic&quot;,
                            eval_metric = &quot;error&quot;, nthread = 1),
                       data = xgb.DMatrix(dtm_train2, 
                                   label = clothing_reviews_train$Liked == &quot;1&quot;),
                       nrounds = 500)</code></pre>
<pre class="r"><code>pred2 &lt;- predict(xgb_model2, dtm_test2)

confusionMatrix(clothing_reviews_test$Liked,
                as.factor(round(pred2, digits = 0)))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1441  630
##          1  426 2200
##                                         
##                Accuracy : 0.7752        
##                  95% CI : (0.763, 0.787)
##     No Information Rate : 0.6025        
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16     
##                                         
##                   Kappa : 0.5392        
##  Mcnemar&#39;s Test P-Value : 4.187e-10     
##                                         
##             Sensitivity : 0.7718        
##             Specificity : 0.7774        
##          Pos Pred Value : 0.6958        
##          Neg Pred Value : 0.8378        
##              Prevalence : 0.3975        
##          Detection Rate : 0.3068        
##    Detection Prevalence : 0.4409        
##       Balanced Accuracy : 0.7746        
##                                         
##        &#39;Positive&#39; Class : 0             
## </code></pre>
<p>Unfortunately, this didn’t really improve the classification accuracy but let’s look at the explanations again:</p>
<pre class="r"><code>explainer2 &lt;- lime(clothing_reviews_train$text, 
                  xgb_model2, 
                  preprocess = create_dtm_mat)</code></pre>
<pre class="r"><code>explanations2 &lt;- lime::explain(clothing_reviews_test$text[1:4], explainer2, n_labels = 1, n_features = 4)
plot_text_explanations(explanations2)</code></pre>
<div id="htmlwidget-2" style="width:100%;height:auto;" class="plot_text_explanations html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"html":"<div style=\"overflow-y:scroll;font-family:sans-serif;position:absolute;height:100%\"> <p>  <span class='negative_1'>Absolutely<\/span> <span class='positive_4'>wonderful<\/span> - <span class='negative_1'>silky<\/span> and sexy and <span class='positive_2'>comfortable<\/span> <\/br> <sub>Label predicted: 1 (97.25%)<br/>Explainer fit: 0.94<\/sub> <\/p><br/><p> Some major <span class='positive_2'>design<\/span> flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. <span class='positive_1'>overall<\/span>, the top half was <span class='negative_2'>comfortable<\/span> and fit nicely, but the bottom half had a very tight under layer and several somewhat <span class='positive_2'>cheap<\/span> (net) over layers. imo, a major <span class='positive_2'>design<\/span> flaw was the net over layer sewn directly into the zipper - it c <\/br> <sub>Label predicted: 0 (94.56%)<br/>Explainer fit: 0.34<\/sub> <\/p><br/><p> Flattering shirt This shirt is very <span class='positive_2'>flattering<\/span> to all due to the adjustable front tie. it is the <span class='positive_2'>perfect<\/span> length to <span class='negative_1'>wear<\/span> with leggings and it is sleeveless so it pairs well with any cardigan. <span class='positive_2'>love<\/span> this shirt!!! <\/br> <sub>Label predicted: 1 (98.61%)<br/>Explainer fit: 0.62<\/sub> <\/p><br/><p> <span class='positive_2'>Pretty<\/span> party dress with some <span class='positive_2'>issues<\/span> This is a nice choice for holiday gatherings. i like that the length grazes the knee so it is conservative enough for office related gatherings. the size small fit me well - i am usually a size 2/4 with a small bust. in my opinion it runs small and those with larger busts will definitely have to size up (but then perhaps the waist will be too big). the <span class='positive_2'>problem<\/span> with this dress is the quality. the fabrics are terrible. the <span class='negative_1'>delicate<\/span> netting type fabric on the top layer of skirt got stuck in the zip <\/br> <sub>Label predicted: 0 (98.61%)<br/>Explainer fit: 0.44<\/sub> <\/p> <\/div>"},"evals":[],"jsHooks":[]}</script>
<p><br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br></p>
<p>The words that get picked up now make much more sense! So, even though making my model more complex didn’t improve “the numbers”, this second model is likely to be much better able to generalize to new reviews because it seems to pick up on words that make intuitive sense.</p>
<p>That’s why I’m sold on the benefits of adding explainer functions to most machine learning workflows - and why I love the <code>lime</code> package in R!</p>
<hr />
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] bindrcpp_0.2.2  lime_0.4.0      xgboost_0.71.2  caret_6.0-80   
##  [5] lattice_0.20-35 text2vec_0.5.1  ggthemes_3.5.0  forcats_0.3.0  
##  [9] stringr_1.3.1   dplyr_0.7.6     purrr_0.2.5     readr_1.1.1    
## [13] tidyr_0.8.1     tibble_1.4.2    ggplot2_3.0.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2     class_7.3-14         rprojroot_1.3-2     
##   [4] futile.logger_1.4.3  pls_2.6-0            rstudioapi_0.7      
##   [7] DRR_0.0.3            SnowballC_0.5.1      prodlim_2018.04.18  
##  [10] lubridate_1.7.4      xml2_1.2.0           codetools_0.2-15    
##  [13] splines_3.5.1        mnormt_1.5-5         robustbase_0.93-1   
##  [16] knitr_1.20           shinythemes_1.1.1    RcppRoll_0.3.0      
##  [19] mlapi_0.1.0          jsonlite_1.5         broom_0.4.5         
##  [22] ddalpha_1.3.4        kernlab_0.9-26       sfsmisc_1.1-2       
##  [25] shiny_1.1.0          compiler_3.5.1       httr_1.3.1          
##  [28] backports_1.1.2      assertthat_0.2.0     Matrix_1.2-14       
##  [31] lazyeval_0.2.1       cli_1.0.0            later_0.7.3         
##  [34] formatR_1.5          htmltools_0.3.6      tools_3.5.1         
##  [37] NLP_0.1-11           gtable_0.2.0         glue_1.2.0          
##  [40] reshape2_1.4.3       Rcpp_0.12.17         slam_0.1-43         
##  [43] cellranger_1.1.0     nlme_3.1-137         blogdown_0.6        
##  [46] iterators_1.0.9      psych_1.8.4          timeDate_3043.102   
##  [49] gower_0.1.2          xfun_0.3             rvest_0.3.2         
##  [52] mime_0.5             stringdist_0.9.5.1   DEoptimR_1.0-8      
##  [55] MASS_7.3-50          scales_0.5.0         ipred_0.9-6         
##  [58] hms_0.4.2            promises_1.0.1       parallel_3.5.1      
##  [61] lambda.r_1.2.3       yaml_2.1.19          rpart_4.1-13        
##  [64] stringi_1.2.3        foreach_1.4.4        e1071_1.6-8         
##  [67] lava_1.6.2           geometry_0.3-6       rlang_0.2.1         
##  [70] pkgconfig_2.0.1      evaluate_0.10.1      bindr_0.1.1         
##  [73] labeling_0.3         recipes_0.1.3        htmlwidgets_1.2     
##  [76] CVST_0.2-2           tidyselect_0.2.4     plyr_1.8.4          
##  [79] magrittr_1.5         bookdown_0.7         R6_2.2.2            
##  [82] magick_1.9           dimRed_0.1.0         pillar_1.2.3        
##  [85] haven_1.1.2          foreign_0.8-70       withr_2.1.2         
##  [88] survival_2.42-3      abind_1.4-5          nnet_7.3-12         
##  [91] modelr_0.1.2         crayon_1.3.4         futile.options_1.0.1
##  [94] rmarkdown_1.10       grid_3.5.1           readxl_1.1.0        
##  [97] data.table_1.11.4    ModelMetrics_1.1.0   digest_0.6.15       
## [100] tm_0.7-4             xtable_1.8-2         httpuv_1.4.4.2      
## [103] RcppParallel_4.4.0   stats4_3.5.1         munsell_0.5.0       
## [106] glmnet_2.0-16        magic_1.5-8</code></pre>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/machine-learning/">machine learning</a>

  <a class="tag tag--primary tag--small" href="//tags/xgboost/">xgboost</a>

  <a class="tag tag--primary tag--small" href="//tags/lime/">lime</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/07/explaining_ml_models_code_caret_iml/" data-tooltip="Explaining Black-Box Machine Learning Models - Code Part 1: tabular data &#43; caret &#43; iml">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Dr. Shirin Glander. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/07/explaining_ml_models_code_caret_iml/" data-tooltip="Explaining Black-Box Machine Learning Models - Code Part 1: tabular data &#43; caret &#43; iml">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/07/explaining_ml_models_code_text_lime/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F07%2Fexplaining_ml_models_code_text_lime%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F07%2Fexplaining_ml_models_code_text_lime%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F07%2Fexplaining_ml_models_code_text_lime%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Dr. Shirin Glander</h4>
    
      <div id="about-card-bio">Biologist turned Bioinformatician turned Data Scientist</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Münster, Germany
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/07/explaining_ml_models_code_text_lime/">
                <h3 class="media-heading">Explaining Black-Box Machine Learning Models - Code Part 2: Text classification with LIME</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:

Explaining supervised classification models built on tabular data using caret and the iml package Explaining image classification models with keras and lime Explaining text classification models with xgboost and lime</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/07/explaining_ml_models_code_caret_iml/">
                <h3 class="media-heading">Explaining Black-Box Machine Learning Models - Code Part 1: tabular data &#43; caret &#43; iml</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">This is code that will encompany an article that will appear in a special edition of a German IT magazine. The article is about explaining black-box machine learning models. In that article I’m showcasing three practical examples:

Explaining supervised classification models built on tabular data using caret and the iml package Explaining image classification models with keras and lime Explaining text classification models with xgboost and lime</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/07/mcubed_mlsummit_data2day/">
                <h3 class="media-heading">My upcoming conference talks &amp; workshops: M-cubed, ML Summit &amp; data2day</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I’ll be giving talks and workshops at the following three upcoming conferences; hope to meet some of you there!

 From 15th to 17th October 2018, I’ll be in London for the M-cubed conference. My talk about Explaining complex machine learning models with LIME will take place on October 16   Traditional machine learning workflows focus heavily on model training and optimization; the best model is usually chosen via performance measures like accuracy or error and we tend to assume that a model is good enough for deployment if it passes certain thresholds of these performance criteria.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/googlelanguager/">
                <h3 class="media-heading">Addendum: Text-to-Speech with the googleLanguageR package</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">After posting my short blog post about Text-to-speech with R, I got two very useful tips. One was to use the googleLanguageR package, which uses the Google Cloud Text-to-Speech API.
And indeed, it was very easy to use and the resulting audio sounded much better than what I tried before!
Here’s a short example of how to use the package for TTS:
Set up Google Cloud and authentification You first need to set up a Google Cloud Account and provide credit card information (the first year is free to use, though).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/intro_to_ml_workshop_heidelberg/">
                <h3 class="media-heading">Code for Workshop: Introduction to Machine Learning with R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">These are the slides from my workshop: Introduction to Machine Learning with R which I gave at the University of Heidelberg, Germany on June 28th 2018. The entire code accompanying the workshop can be found below the video.
The workshop covered the basics of machine learning. With an example dataset I went through a standard machine learning workflow in R with the packages caret and h2o:
 reading in data exploratory data analysis missingness feature engineering training and test split model training with Random Forests, Gradient Boosting, Neural Nets, etc.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/text_to_speech_r/">
                <h3 class="media-heading">Text-to-speech with R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Computers started talking to us! They do this with so called Text-to-Speech (TTS) systems. With neural nets, deep learning and lots of training data, these systems have gotten a whole lot better in recent years. In some cases, they are so good that you can’t distinguish between human and machine voice.
In one of our recent codecentric.AI videos, we compared different Text-to-Speech systems (the video is in German, though - but the text snippets and their voice recordings we show in the video are a mix of German and English).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/keras_fruits_lime/">
                <h3 class="media-heading">Explaining Keras image classification models with lime</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Last week I published a blog post about how easy it is to train image classification models with Keras.
What I did not show in that post was how to use the model for making predictions. This, I will do here. But predictions alone are boring, so I’m adding explanations for the predictions using the lime package.
I have already written a few blog posts (here, here and here) about LIME and have given talks (here and here) about it, too.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/twimlai138/">
                <h3 class="media-heading">Sketchnotes from TWiML&amp;AI: Practical Deep Learning with Rachel Thomas</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Practical Deep Learning with Rachel Thomas:
Sketchnotes from TWiMLAI talk: Practical Deep Learning with Rachel Thomas
 You can listen to the podcast here.
 In this episode, i’m joined by Rachel Thomas, founder and researcher at Fast AI. If you’re not familiar with Fast AI, the company offers a series of courses including Practical Deep Learning for Coders, Cutting Edge Deep Learning for Coders and Rachel’s Computational Linear Algebra course.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/06/keras_fruits/">
                <h3 class="media-heading">It&#39;s that easy! Image classification with keras in roughly 100 lines of code.</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I’ve been using keras and TensorFlow for a while now - and love its simplicity and straight-forward way to modeling. As part of the latest update to my Workshop about deep learning with R and keras I’ve added a new example analysis:
Building an image classifier to differentiate different types of fruits
And I was (again) suprised how fast and easy it was to build the model; it took not even half an hour and only around 100 lines of code (counting only the main code; for this post I added comments and line breaks to make it easier to read)!</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/05/ropensci_unconf18/">
                <h3 class="media-heading">rOpenSci unconference 2018 &#43; introduction to TensorFlow Probability &amp; the &#39;greta&#39; package</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">On May 21st and 22nd, I had the honor of having been chosen to attend the rOpenSci unconference 2018 in Seattle. It was a great event and I got to meet many amazing people!
rOpenSci rOpenSci is a non-profit organisation that maintains a number of widely used R packages and is very active in promoting a community spirit around the R-world. Their core values are to have open and reproducible research, shared data and easy-to-use tools and to make all this accessible to a large number of people.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         51 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/autumn-2789234_1920.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/07\/explaining_ml_models_code_text_lime\/';
          
            this.page.identifier = '\/2018\/07\/explaining_ml_models_code_text_lime\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'shirinsplayground';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

