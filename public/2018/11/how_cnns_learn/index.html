

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.27 with theme Tranquilpeak 0.4.1-BETA">
    <title>How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example</title>
    <meta name="author" content="Dr. Shirin Glander">
    <meta name="keywords" content=", R">

    <link rel="icon" href="img/favicon.png">
    

    
    <meta name="description" content="As with the other videos from our codecentric.ai Bootcamp (Random Forests, Neural Nets &amp; Gradient Boosting), I am again sharing an English version of the script (plus R code) for this most recent addition on How Convolutional Neural Nets work.
In this lesson, I am going to explain how computers learn to see; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are Convolutional Neural Nets.">
    <meta property="og:description" content="As with the other videos from our codecentric.ai Bootcamp (Random Forests, Neural Nets &amp; Gradient Boosting), I am again sharing an English version of the script (plus R code) for this most recent addition on How Convolutional Neural Nets work.
In this lesson, I am going to explain how computers learn to see; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are Convolutional Neural Nets.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example">
    <meta property="og:url" content="/2018/11/how_cnns_learn/">
    <meta property="og:site_name" content="Shirin&#39;s playgRound">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Shirin&#39;s playgRound">
    <meta name="twitter:description" content="As with the other videos from our codecentric.ai Bootcamp (Random Forests, Neural Nets &amp; Gradient Boosting), I am again sharing an English version of the script (plus R code) for this most recent addition on How Convolutional Neural Nets work.
In this lesson, I am going to explain how computers learn to see; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are Convolutional Neural Nets.">
    
      <meta name="twitter:creator" content="@ShirinGlander">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=640">
    

    
      <meta property="og:image" content="https://shiring.github.io/netlify_images/cnn_yt_video.png">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-hbs5om8csx9a8yrv5hnhpi2qqdv4ykuslajwbramhqxvleqbfklxgek50hye.min.css" />
    
    

    
      
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-86119417-1', 'auto');
ga('send', 'pageview');
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Shirin&#39;s playgRound</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <h1 class="sidebar-profile-title">How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example</h1>
        <a href="https://blog.feedspot.com/r_programming_blogs/" rel="nofollow" title="R Programming Blogs"><img alt="R Programming Blogs" src="https://blog.feedspot.com/wp-content/uploads/2018/04/r_program_216px.png?x20694"/></a>
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Dr. Shirin Glander</h4>
        
          <h5 class="sidebar-profile-bio">Biologist turned Bioinformatician turned Data Scientist</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags/">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/about/">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/conferences_podcasts_webinars/">
    
      <i class="sidebar-button-icon fa fa-lg fa-bullhorn"></i>
      
      <span class="sidebar-button-desc">Hear me talk</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://shiring.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">My old R-blog</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.codecentric.de/kuenstliche-intelligenz/">
    
      <i class="sidebar-button-icon fa fa-lg fa-angle-double-right"></i>
      
      <span class="sidebar-button-desc">codecentric.ai</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/ShirinG">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/shirin-glander-01120881/">
    
      <i class="sidebar-button-icon fa fa-lg fa-linkedin"></i>
      
      <span class="sidebar-button-desc">LinkedIn</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stackoverflow.com/users/6623620/shirin-glander">
    
      <i class="sidebar-button-icon fa fa-lg fa-stack-overflow"></i>
      
      <span class="sidebar-button-desc">Stack Overflow</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://twitter.com/ShirinGlander">
    
      <i class="sidebar-button-icon fa fa-lg fa-twitter"></i>
      
      <span class="sidebar-button-desc">Twitter</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.xing.com/profile/Shirin_Glander">
    
      <i class="sidebar-button-icon fa fa-lg fa-xing"></i>
      
      <span class="sidebar-button-desc">Xing</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.meetup.com/Munster-R-Users-Group">
    
      <i class="sidebar-button-icon fa fa-lg fa-meetup"></i>
      
      <span class="sidebar-button-desc">MünsteR</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-bloggers</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-users.com/">
    
      <i class="sidebar-button-icon fa fa-lg fa-book"></i>
      
      <span class="sidebar-button-desc">R-users</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaOut
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-11-29T00:00:00Z">
        
  November 29, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>As with the other videos from our <a href="https://bootcamp.codecentric.ai/">codecentric.ai Bootcamp</a> (<a href="https://shirinsplayground.netlify.com/2018/10/ml_basics_rf/">Random Forests</a>, <a href="https://shirinsplayground.netlify.com/2018/11/neural_nets_explained/">Neural Nets</a> &amp; <a href="https://shirinsplayground.netlify.com/2018/11/ml_basics_gbm/">Gradient Boosting</a>), I am again sharing an English version of the script (plus R code) for this most recent addition on <a href="https://youtu.be/MWPohcMtFLo">How Convolutional Neural Nets work</a>.</p>
<hr />
<p>In this lesson, I am going to explain <strong>how computers learn to see</strong>; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are <strong>Convolutional Neural Nets</strong>.</p>
<p>This lesson builds on top of two other lessons: <a href="https://youtu.be/JS4E04dJj0I">Computer Vision Basics</a> and <a href="https://shirinsplayground.netlify.com/2018/11/neural_nets_explained/">Neural Nets</a>. In the first video, Oli explains what computer vision is, how images are read by computers and how they can be analyzed with traditional approaches, like <strong>Histograms of Oriented Gradients</strong> and more. He also shows a very cool project, that he and colleagues worked on, where they programmed a small drone to recognize and avoid obstacles, like people. This video is only available in German, though. In the Neural Nets blog post, I show how Neural Nets work by explaining what <strong>Multi-Layer Perceptrons (MLPs)</strong> are and how they learn, using techniques like <strong>gradient descent</strong>, <strong>backpropagation</strong>, <strong>loss</strong> and <strong>activation functions</strong>.</p>
<p>Convolutional Neural Nets are usually abbreviated either <strong>CNNs</strong> or <strong>ConvNets</strong>. They are a specific type of neural network that has very particular differences compared to MLPs. Basically, you can think of CNNs as working similarly to the <strong>receptive fields of photoreceptors</strong> in the human eye. Receptive fields in our eyes are small connected areas on the retina where groups of many photoreceptors stimulate much fewer ganglion cells. Thus, each ganglion cell can be stimulated by a large number of receptors, so that a complex input is condensed into a <strong>compressed output</strong> before it is further processed in the brain.</p>
<p>Before we dive deeper into CNNs, I briefly want to recap how images can take on a numerical format. We need a numerical representation of our image because just like any other machine learning model or neural net, CNNs need data in form of numbers in order to learn! With images, these numbers are <strong>pixel values</strong>; when we have a greyscale image, these values represent a range of “greyness” from 0 (black) to 255 (white).</p>
<p>Here is an example image from the fruits datasets, which is used in the <a href="https://shirinsplayground.netlify.com/2018/06/keras_fruits/">practical example for this lesson</a>. In general, data can be represented in different formats, e.g. as vectors, tables or matrices. I am using the <code>imager</code> package to read the image and have a look at the pixel values, which are represented as a <strong>matrix with the dimensions image width x image height</strong>.</p>
<pre class="r"><code>library(imager)
im &lt;- load.image(&quot;/Users/shiringlander/Documents/Github/codecentric.AI-bootcamp/data/fruits-360/Training/Strawberry/100_100.jpg&quot;)</code></pre>
<pre class="r"><code>plot(im)</code></pre>
<p><img src="/post/how_cnns_learn_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>But when we look at the <code>dim()</code> function with our image, we see that there are actually four dimensions and only the first two represent image width and image height. The third dimension is for the depth, which means in case of videos the time or order of the frames; with regular images, we don’t need this dimension. The third dimension shows the number of <strong>color channels</strong>; in this case, we have a color image, so there are three channels for red, green and blue. The values remain in the same between 0 and 255 but now they don’t represent greyscales but color intensity of the respective channel. This 3-dimensional format (a stack of three matrices) is also called a 3-dimensional <strong>array</strong>.</p>
<pre class="r"><code>dim(im)</code></pre>
<pre><code>## [1] 100 100   1   3</code></pre>
<p>Let’s see what happens if we convert our image to greyscale:</p>
<pre class="r"><code>im_grey &lt;- grayscale(im)
plot(im_grey)</code></pre>
<p><img src="/post/how_cnns_learn_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Our grey image has only one channel.</p>
<pre class="r"><code>dim(im_grey)</code></pre>
<pre><code>## [1] 100 100   1   1</code></pre>
<p>When we look at the actual matrix of pixel values (below, shown with a subset), we see that our values are not shown as raw values, but as scaled values between 0 and 1.</p>
<pre class="r"><code>head(as.array(im_grey)[25:75, 25:75, 1, 1])</code></pre>
<pre><code>##           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
## [1,] 0.2015294 0.1923529 0.2043529 0.2354902 0.2021961 0.2389804 0.2431373
## [2,] 0.2597647 0.2009804 0.2522745 0.3812941 0.2243137 0.2439608 0.2054902
## [3,] 0.2872941 0.2397255 0.3251765 0.5479608 0.3723922 0.2525882 0.2714510
## [4,] 0.2212549 0.2596078 0.5109020 0.2871765 0.5529412 0.2162745 0.5660000
## [5,] 0.2725882 0.3765882 0.2081569 0.1924314 0.3110196 0.3767843 0.6663922
## [6,] 0.4154118 0.2168627 0.2979216 0.1883922 0.1836471 0.5210196 0.4032549
##           [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
## [1,] 0.2787059 0.2401961 0.2547451 0.2709020 0.2475686 0.2474118 0.2561961
## [2,] 0.2407451 0.2520392 0.3678039 0.3932941 0.3570588 0.3727843 0.3171765
## [3,] 0.5352157 0.4680392 0.2788627 0.2087451 0.2096471 0.2569412 0.2856863
## [4,] 0.2663137 0.1769020 0.2441961 0.2172549 0.2004314 0.2517255 0.2801961
## [5,] 0.2470980 0.1892549 0.2169020 0.2211765 0.2041569 0.1972549 0.1933725
## [6,] 0.2209412 0.1961961 0.2166275 0.2123137 0.2503922 0.3057255 0.3998431
##          [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]
## [1,] 0.2330980 0.2163529 0.2244706 0.2161961 0.1913725 0.2833725 0.1994902
## [2,] 0.2316863 0.2426275 0.2131765 0.2018431 0.2054902 0.2452157 0.2080392
## [3,] 0.2290196 0.2086667 0.2161176 0.2283922 0.2447059 0.2281176 0.2908627
## [4,] 0.2605882 0.2009412 0.2431765 0.4591765 0.6387843 0.3078824 0.2486275
## [5,] 0.1975686 0.2092549 0.2742745 0.4005882 0.3773333 0.2245490 0.2474902
## [6,] 0.3936471 0.1815294 0.1930980 0.2084706 0.5097647 0.3130196 0.2153333
##          [,22]     [,23]     [,24]     [,25]     [,26]     [,27]     [,28]
## [1,] 0.2122353 0.2283529 0.4250980 0.4372157 0.2789020 0.2011373 0.2278431
## [2,] 0.1925098 0.2745098 0.3172157 0.4366667 0.3427451 0.2161176 0.2557647
## [3,] 0.2150588 0.2788627 0.2544314 0.3665882 0.3292157 0.2121176 0.2092157
## [4,] 0.2119216 0.2029020 0.2005098 0.2485882 0.2550588 0.2402745 0.2172549
## [5,] 0.2466275 0.1983137 0.2108627 0.2305098 0.3066667 0.3615686 0.3726275
## [6,] 0.2040000 0.2472549 0.2114510 0.1891765 0.2429020 0.2867451 0.2863529
##          [,29]     [,30]     [,31]     [,32]     [,33]     [,34]     [,35]
## [1,] 0.2782353 0.3150980 0.3993725 0.3683922 0.3249804 0.3210588 0.3150588
## [2,] 0.2593333 0.2162353 0.2950588 0.4864706 0.4195294 0.4238039 0.3776863
## [3,] 0.2314510 0.2311765 0.2737255 0.3915686 0.3851765 0.4050588 0.4233725
## [4,] 0.2583922 0.2953333 0.3530196 0.3609412 0.4549020 0.4880000 0.4905882
## [5,] 0.4509804 0.5030980 0.4882745 0.4000784 0.4856863 0.6270196 0.5930196
## [6,] 0.2034118 0.1965882 0.2072157 0.2238824 0.2080392 0.2009804 0.5564314
##          [,36]     [,37]     [,38]     [,39]     [,40]     [,41]     [,42]
## [1,] 0.2461961 0.2352549 0.2726275 0.2752549 0.2603529 0.3112549 0.3981176
## [2,] 0.2441961 0.2152157 0.2407059 0.2647451 0.2650196 0.2767451 0.3592549
## [3,] 0.2318039 0.2348235 0.2612157 0.2647059 0.2647059 0.2958431 0.3112549
## [4,] 0.2630588 0.1901176 0.2414510 0.2483529 0.2601961 0.2713725 0.3139216
## [5,] 0.3403529 0.2250588 0.2315294 0.1954510 0.2704314 0.3076078 0.3111765
## [6,] 0.4018039 0.2904706 0.3806275 0.4549020 0.3765098 0.4278824 0.4952941
##          [,43]     [,44]     [,45]     [,46]     [,47]     [,48]     [,49]
## [1,] 0.3724706 0.3154902 0.3728627 0.3653333 0.3758824 0.4943922 0.4682353
## [2,] 0.3664706 0.3616863 0.3263922 0.2882745 0.2752157 0.2451373 0.3379608
## [3,] 0.3309804 0.2837647 0.2366275 0.2718039 0.2713725 0.2832549 0.2749020
## [4,] 0.3819216 0.3143137 0.2364706 0.2324314 0.2685098 0.2722745 0.2324706
## [5,] 0.2989804 0.2561176 0.2748627 0.3621961 0.5355686 0.4248235 0.6004314
## [6,] 0.4528627 0.3580392 0.2934118 0.4385098 0.2146275 0.2045882 0.2243922
##          [,50]     [,51]
## [1,] 0.3378039 0.2782353
## [2,] 0.2750980 0.3264314
## [3,] 0.2761961 0.3800000
## [4,] 0.3410980 0.5016863
## [5,] 0.6163922 0.6553333
## [6,] 0.2436471 0.2944706</code></pre>
<p>The same applies to the color image, which if multiplied with 255 shows raw pixel values:</p>
<pre class="r"><code>head(as.array(im)[25:75, 25:75, 1, 1]  * 255)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
## [1,]  138  142  150  161  151  155  153  161  158   156   155   144   143
## [2,]  159  139  147  183  152  159  135  127  144   174   177   164   162
## [3,]  170  140  143  200  172  150  139  184  185   148   139   133   134
## [4,]  142  138  189  130  204  119  200  114  114   148   152   141   140
## [5,]  138  172  139  133  145  146  220  122  132   149   153   140   127
## [6,]  170  141  184  155  127  190  162  129  147   150   144   148   155
##      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
## [1,]   148   149   150   152   143   130   156   145   154   151   191
## [2,]   148   136   156   158   148   135   141   139   143   161   165
## [3,]   140   139   148   153   146   138   132   155   143   161   153
## [4,]   147   157   152   155   190   226   147   146   145   141   137
## [5,]   128   143   157   164   172   151   120   147   161   143   134
## [6,]   179   187   144   144   132   190   143   136   147   156   135
##      [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35]
## [1,]   190   157   141   139   144   152   176   167   150   149   159
## [2,]   177   170   153   162   152   136   155   197   167   164   162
## [3,]   162   165   148   147   146   140   144   163   147   151   170
## [4,]   143   149   147   138   143   148   157   149   165   172   185
## [5,]   150   165   172   169   185   197   193   169   187   216   206
## [6,]   143   149   152   147   125   123   127   137   133   120   198
##      [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46]
## [1,]   154   155   159   153   145   155   170   159   149   171   170
## [2,]   148   150   152   147   139   149   163   162   168   166   153
## [3,]   142   155   159   153   146   165   162   165   159   150   153
## [4,]   144   138   154   153   153   156   166   184   170   150   143
## [5,]   151   137   150   138   152   147   152   156   151   156   173
## [6,]   161   150   185   199   166   171   189   184   168   159   196
##      [,47] [,48] [,49] [,50] [,51]
## [1,]   170   200   200   174   165
## [2,]   143   135   167   160   176
## [3,]   146   148   150   150   174
## [4,]   148   149   139   159   190
## [5,]   215   191   237   233   229
## [6,]   136   133   141   143   148</code></pre>
<p>These pixel arrays of our images are now the input to our CNN, which can now learn to recognize e.g. which fruit is on each image (a classification task). This is accomplished by learning different levels of abstraction of the images. In the first few hidden layers, the CNN ususally detects general patterns, like edges; the deeper we go into the CNN, these learned abstractions become more specific, like textures, patterns and (parts of) objects.</p>
<p>We could also train MLPs on our images but usually, they are not very good at this sort of task. So, what’s the magic behind CNNs, that makes them so much more powerful at detecting images and object?</p>
<div id="the-most-important-difference-is-that-mlps-consider-each-pixel-position-as-an-independent-feature-it-does-not-know-neighboring-pixels-thats-why-mlps-will-not-be-able-to-detect-images-where-the-objects-have-a-different-orientation-position-etc.-moreover-because-we-often-deal-with-large-images-the-sheer-number-of-trainable-parameters-in-an-mlp-will-quickly-escalate-so-that-training-such-a-network-isnt-exactly-efficient.-in-mlps-weights-are-learned-e.g.with-gradient-descent-and-backpropagation." class="section level2">
<h2>The most important difference is that MLPs consider each pixel position as an independent feature; it does not know neighboring pixels! That’s why MLPs will not be able to detect images where the objects have a different orientation, position, etc. Moreover, because we often deal with large images, the sheer number of trainable parameters in an MLP will quickly escalate, so that training such a network isn’t exactly efficient. In MLPs, <strong>weights</strong> are learned, e.g. with gradient descent and backpropagation.</h2>
<p>Bei CNNs werden dagegen Gruppen aus benachbarten Pixeln betrachtet. Das bezeichnen wir als “Local connectivity”, denn in unserem Neuronalen Netz sind Neuronen später zunächst nur mit den lokal entsprechenden Neuronen in den Folgeschichten verbinden. Dadurch kann das Netz effizient und relativ schnell den Kontext von Mustern und Objekten lernen und diese auch in anderen Postionen auf dem Bild erkennen. Konkret funktionert das mit sogenannten Sliding Windows, also Fenstern, die eine Gruppe von Pixeln betrachten und dabei von links oben nach rechts unten das Bild abscannen. Gelernt werden dabei dann auch keine Gewichte, sondern Filter. Was diese Filter sind, erkläre ich im nächsten Schritt. Übrigens können wir CNNs nicht nur für Bilder, sondern auch sehr gut für andere Aufgaben, wie Textklassifikation verwenden.</p>
<hr />
<p>Auf jedem Fenster des Sliding Windows,</p>
<p>das zu Beispiel eine Größe</p>
<p>von 3 x 3 Pixeln haben kann,</p>
<p>wird nämlich nun eine bestimmt mathematische Operation durchgeführt, die sogenannte Faltung - oder auf Englisch: convolution. Daher also auch der Name… ;-)</p>
<p>Diese Faltung passiert für jedes Fenster des gesamten Bildes.</p>
<p>…</p>
<p>In diesem Video, das ihr vielleicht schon aus den Computer Vision Basics kennt, ist das einmal animiert gezeigt.</p>
<p>Aber was ist nun diese Faltung? Die Faltung passiert über das Multiplizieren der Pixelwerte in unserem Fenster mit einem sogenannten Filter. Dieser Filter ist nichts anderes als eine Matrix mit den selben Dimensionen des Sliding Windows, hier 3 x 3. Je nachdem, welche Werte in einem Filter stehen, führt die Faltung zu einer bestimmten Transformation des Originalbildes. Hier ist der Filter für das Schärfen von Bildern zu sehen.</p>
<p>Das Ganze läuft nun so ab, wie in dieser großartigen Abbildung von setosa.io zu sehen ist. Das linke Bild ist das Original, das rechte zeigt das transformierte Bild nach Anwendung des Filters.</p>
<p>Die Pixel des Fensters, das gerade betrachtete wird sind in den Kästchen in der Mitte zu sehen. Jeder Pixelwert in dem Fenster wird nun mit dem Wert an der entprechenden Stelle im Filter multipliziert und mit allen anderen so multiplizierten Werten aufaddiert. Das Ergebnis ist hier -97 und ist der neue Wert für das transformierte Bild.</p>
<hr />
<p>Zwei wichtige Hyperparameter für CNNs sind Padding und die Schrittgröße.</p>
<p>Padding bezeichnet das Hinzufügen von extra Pixelschichten am Rand des Bildes, damit jeder Pixel des eigentlichen Bildes beim scannen des Sliding Windows gleich häufig gefaltet wird. Würden wir kein Padding anwenden, würden die Randpixel weniger häufig betrachtet, als die Pixel in der Mitte des Bildes - und unser Bild würde nach der Transformation kleiner werden. Es gibt mehrere Arten von Padding. Bei “same” werden die Randpixel dupliziert</p>
<p>und an an den Rand</p>
<p>hinzugefügt. Alternativ könnten wir die Ränder auch mit Nullern auffüllen, dem sogenannten Zero-Padding.</p>
<p>Jetzt kann das Sliding Window oben link starten.</p>
<p>Die Schrittgröße bezeichnet nun, wie weit das Sliding Window bei jedem Schritt vorrückt. Meisten wird eine Schrittgröße von 1 verwendet, d.h. dass das Sliding Window nach jeder Faltung jeweils einen Pixel weiterwandert. Würden wir die Schrittgröße vergrößern, würde die Berechnung des neuronalen Netzes schneller gehen, wir würden aber auch nicht so detaillierte Muster erkennen können. Und unser Bild würde sich im Output verkleinern.</p>
<hr />
<p>Kommen wir aber noch mal zurück zu den Filtern. Manchmal werden Filter, bzw. Fenster auch als Kernel oder Filter Kernel bezeichnet. Tatsächlich sind Filter Sammlungen von Kernels, d.h. wenn wir mit Farbbildern und 3 Kanälen - also 3 Dimensionen - arbeiten, haben wir einen Kernel pro Kanal, aus dem sich ein Filter zusammensetzt. Pro Filter bekommen wir dann EINEN Ergebniswert aus dem Skalarprodukt zurück! Beispiele für andere Filter können zum Beispiel das Originalbild verwaschen,</p>
<p>untere</p>
<p>oder obere horizontale Kanten erkennen.</p>
<p>Im Prinzip können aber beliebige Werte in die Filter eingesetzt werden,</p>
<p>so dass verschiedenste Muster in dem Bild hervortreten. Jedes Muster stellt eine sogenannte Feature Map oder Activation Map dar. Die Werte, die an den einzelnen Stellen des Filters stehen, sollen jetzt von unserem neuronalen Netz gelernt werden. Das CNN lernt also, welche Transformation es wann durchführen muss, um die richtigen Muster und Objekte in den Bildern zu erkennen. Dafür lernt das CNN nicht nur einen Filter, sondern sehr sehr viele. Es lernt sogar in jeder versteckten SCHICHT mehrere Filter parallel.</p>
<p>Diese unabhängig voneinander parallel gelernten Filter, bzw. die transformierten Output-Bilder nach der Faltung, produzieren die sogenannten</p>
<p>Stacks of Feature Maps oder Activation Maps. Die Anzahl der zu trainierenden Parameter ist bei Faltungen deutlich geringer als bei voll verknüpften Neuronen in MLPs. In den Beispielen, die ich hier gezeigt habe, haben wir Graustufenbilder und 2-dimensionale Filter gesehen. Bei Farbbildern mit 3 Farbkanälen hätten wir entsprechend 3-dimensionale Filter, die das Ergbenis ebenfalls mit dem Skalarprodukt aus Filter und Bildausschnitt berechnen.</p>
<hr />
<p>Wie CNNs LERNEN Bilder mit Hilfe von Filtern und Faltungen zu erkennen, haben wir jetzt gesehen. CNN-Architekturen bestehen aber nicht nur aus Schichten, in denen Faltung passiert, den Convolutional Layern, sondern sie haben zusätzlich sogenannte Pooling Schichten. In den Pooling Schichten werden die Bilder (also die transformierten Outputs aus vorhergehenden Faltungsschichten) verkleinert.</p>
<p>Dafür wird auch wieder ein Sliding Window verwendet, dieses muss nicht die selbe Größe haben, wie das Sliding Window aus den Faltungsschichten aber hier zeige ich das Prinzip beispielhaft ebenfalls an einem 3 x 3 Fenster. Wichtig ist dabei, dass das Sliding Window beim Pooling meist nicht überlappt, sondern jeder Pixel genau 1x betrachtet wird, damit das Output-Bild entsprechend kleiner wird.</p>
<p>Es gibt mehrere Arten, wie Bilder mit Pooling verkleinert werden können. Die häufigsten sind</p>
<p>Max Pooling, wo nur der größte Wert jedes Fensters behalten wird,</p>
<p>Average Pooling, wo der Durschschnittswert aus jedem Fenster gebildet wird</p>
<p>und Sum Pooling, wo die Summe aller Werte gebildet wird. Pooling arbeitet dabei unabhängig auf jeder einzelnen Feature Map und sorgt nicht nur für eine Reduktion des Bildes und damit an zu optimierenden Parametern, sondern hilft auch dabei, allgemeingültige Feature zu extrahieren, die robust gegenüber kleineren Änderungen des Inputs sind.</p>
<hr />
<p>Okay, setzen wir nun also die Faltungsschichten und Pooling-Schichten zu einer typischen CNN-Architektur zusammen.</p>
<p>Wir starten natürlich wie immer mit dem Input, in unserem Fall Bilder.</p>
<p>Nun kommt in der Regel 1 oder 2 Faltungsschichten (plus Aktivierungsfunktion nach jeder Faltung, z.B. Rectified Linear Units),</p>
<p>gefolgt von einer Pooling-Schicht.</p>
<p>Von diesen Blöcken aus Convolution und Pooling können nun mehrere hintereinander gefügt werden. In der nächsten Lektion werden wir uns konkrete Beispiele mit unterschiedlich vielen Schichten und Weiterentwicklungen, wie AlexNet, VGG, Inception und ResNets, angucken. In dieser Lektion werden wir uns außerdem angucken, wie wir Activation Maps in unserem Modell visualisieren können.</p>
<p>Bevor wir das Endergbnis, zum Beispiel eine Klasse bestimmen lassen, folgen eine oder ein paar wenige Dense Layer, als würden wir ein kleines MLP hinten dran hängen. In den Dense Layern werden deshab wieder Gewichte gelernt. Im Wesentlichen haben die Faltungsschichten in unserem Netz relevante Feature gefunden, und die Pooling-Schichten habe diese Information soweit verdichtet, dass es nun sinnvoll ist ein MLP zu trainieren, dass in der Lage ist die finale Klassifikation zu lernen.</p>
<p>Und zuletzt haben wir eine Output-Schicht, ebenfalls wie bei einem einfachen MLP.</p>
<hr />
<p>Sicher wollt ihr jetzt wissen, wie ihr selber ein CNN bauen und verwenden könnt. Dafür haben wir euch wieder ein Notebook mit einem Beispiel erstellt. In dieser Lektion verwenden wir Keras und TensorFlow um ein CNN zu trainieren, das Bilder von verschiedenen Früchten erkennen kann.</p>
<p>Hier nur ein kleiner Ausschnitt aus dem Code. Vielleicht erkennt ihr schon Teile aus diesem Video, wie Convolution, padding und pooling?</p>
<p>Die vollständige Erklärung mit Code zum Mitmachen findet ihr in dem Notebook zu diesem Video!</p>
<p>You can find the R version of the Python code, which we provide for this course in <a href="https://shirinsplayground.netlify.com/2018/06/keras_fruits/">this blog article</a>.</p>
<hr />
<p><a href="https://youtu.be/MWPohcMtFLo">Video</a>:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MWPohcMtFLo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p><a href="https://codecentric.slides.com/shiringlander/intro_cnns">Slides</a>:</p>
<iframe src="//codecentric.slides.com/shiringlander/intro_cnns/embed" width="576" height="420" scrolling="no" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen>
</iframe>
<hr />
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS  10.14.2
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] imager_0.41.1 magrittr_1.5 
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.0       bookdown_0.8     png_0.1-7        digest_0.6.18   
##  [5] tiff_0.1-5       plyr_1.8.4       evaluate_0.12    blogdown_0.9    
##  [9] rlang_0.3.0.1    stringi_1.2.4    bmp_0.3          rmarkdown_1.11  
## [13] tools_3.5.1      stringr_1.3.1    purrr_0.2.5      igraph_1.2.2    
## [17] jpeg_0.1-8       xfun_0.4         yaml_2.2.0       compiler_3.5.1  
## [21] pkgconfig_2.0.2  htmltools_0.3.6  readbitmap_0.1.5 knitr_1.21</code></pre>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="//tags/machine-learning/">machine learning</a>

  <a class="tag tag--primary tag--small" href="//tags/deep-learning/">deep learning</a>

  <a class="tag tag--primary tag--small" href="//tags/cnn/">cnn</a>

  <a class="tag tag--primary tag--small" href="//tags/codecentric.ai/">codecentric.ai</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/trust_in_ml_slides_ix/" data-tooltip="Trust in ML models. Slides from TWiML &amp; AI EMEA Meetup &#43; iX Articles">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/ml_basics_gbm/" data-tooltip="Machine Learning Basics - Gradient Boosting &amp; XGBoost">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/11/how_cnns_learn/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/11/how_cnns_learn/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/11/how_cnns_learn/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2018 Dr. Shirin Glander. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/trust_in_ml_slides_ix/" data-tooltip="Trust in ML models. Slides from TWiML &amp; AI EMEA Meetup &#43; iX Articles">
              
                <i class="fa fa-angle-left"></i>
                <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
              </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/ml_basics_gbm/" data-tooltip="Machine Learning Basics - Gradient Boosting &amp; XGBoost">
              
                <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                <i class="fa fa-angle-right"></i>
              </a>
            </li>
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/11/how_cnns_learn/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/11/how_cnns_learn/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/11/how_cnns_learn/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F11%2Fhow_cnns_learn%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F11%2Fhow_cnns_learn%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F11%2Fhow_cnns_learn%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/7f7f818e55624edfef8aa93860a1a3d4?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Dr. Shirin Glander</h4>
    
      <div id="about-card-bio">Biologist turned Bioinformatician turned Data Scientist</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Münster, Germany
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/customer_churn_code/">
                <h3 class="media-heading">Code for case study - Customer Churn with Keras/TensorFlow and H2O</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">This is code that accompanies a book chapter on customer churn that I have written for the German dpunkt Verlag. The book is in German and will probably appear in February: https://www.dpunkt.de/buecher/13208/9783864906107-data-science.html.
The code you find below can be used to recreate all figures and analyses from this book chapter. Because the content is exclusively for the book, my descriptions around the code had to be minimal. But I’m sure, you can get the gist, even without the book.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/trust_in_ml_slides_ix/">
                <h3 class="media-heading">Trust in ML models. Slides from TWiML &amp; AI EMEA Meetup &#43; iX Articles</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Update: There is now a recording of the meetup up on YouTube.
 Here you find my slides the TWiML &amp; AI EMEA Meetup about Trust in ML models, where I presented the Anchors paper by Carlos Guestrin et al..
  I have also just written two articles for the German IT magazin iX about the same topic of Explaining Black-Box Machine Learning Models:
 A short article in the iX 12/2018</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/how_cnns_learn/">
                <h3 class="media-heading">How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">As with the other videos from our codecentric.ai Bootcamp (Random Forests, Neural Nets &amp; Gradient Boosting), I am again sharing an English version of the script (plus R code) for this most recent addition on How Convolutional Neural Nets work.
In this lesson, I am going to explain how computers learn to see; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are Convolutional Neural Nets.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/ml_basics_gbm/">
                <h3 class="media-heading">Machine Learning Basics - Gradient Boosting &amp; XGBoost</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">In a recent video, I covered Random Forests and Neural Nets as part of the codecentric.ai Bootcamp.
In the most recent video, I covered Gradient Boosting and XGBoost.
You can find the video on YouTube and the slides on slides.com. Both are again in German with code examples in Python.
But below, you find the English version of the content, plus code examples in R for caret, xgboost and h2o. :-)</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/slides_demystifying_dl/">
                <h3 class="media-heading">Slides from my talks about Demystifying Big Data and Deep Learning (and how to get started)</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">On November 7th, Uwe Friedrichsen and I gave our talk from the JAX conference 2018: Deep Learning - a Primer again at the W-JAX in Munich.
A few weeks before, I gave a similar talk at two events about Demystifying Big Data and Deep Learning (and how to get started).
Here are the two very similar presentations from these talks:
    </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/keras_fruits_crossvalidation/">
                <h3 class="media-heading">How to use cross-validation with the image data generator in Keras and TensorFlow</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I’ve been using keras and TensorFlow for a while now - and love its simplicity and straight-forward way to modeling. As part of the latest update to my Workshop about deep learning with R and keras I’ve added a new example analysis:
 https://shirinsplayground.netlify.com/2018/06/keras_fruits/
library(keras) library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.7 ## ✔ tidyr 0.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/twimlai_meetup/">
                <h3 class="media-heading">TWIMLAI European Online Meetup about Trust in Predictions of ML Models</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">At the upcoming This week in machine learning and AI European online Meetup, I’ll be presenting and leading a discussion about the Anchors paper, the next generation of machine learning interpretability tools. Come and join the fun! :-)
 Date: Tuesday 4th December 2018 Time: 19:00 PM CET/CEST  Join: https://twimlai.com/meetups/trust-in-predictions-of-ml-models/
 </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/text_classification_keras_data_prep/">
                <h3 class="media-heading">How to prepare data for NLP (text classification) with Keras and TensorFlow</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">In the past, I have written and taught quite a bit about image classification with Keras (e.g. here). Text classification isn’t too different in terms of using the Keras principles to train a sequential or function model. You can even use Convolutional Neural Nets (CNNs) for text classification.
What is very different, however, is how to prepare raw text data for modeling. When you look at the IMDB example from the Deep Learning with R Book, you get a great explanation of how to train the model.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/neural_nets_explained/">
                <h3 class="media-heading">&#39;How do neural nets learn?&#39; A step by step explanation using the H2O Deep Learning algorithm.</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">In my last blogpost about Random Forests I introduced the codecentric.ai Bootcamp. The next part I published was about Neural Networks and Deep Learning. Every video of our bootcamp will have example code and tasks to promote hands-on learning. While the practical parts of the bootcamp will be using Python, below you will find the English R version of this Neural Nets Practical Example, where I explain how neural nets learn and how the concepts and techniques translate to training neural nets in R with the H2O Deep Learning function.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/ml_basics_rf/">
                <h3 class="media-heading">Machine Learning Basics - Random Forest</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">A few colleagues of mine and I from codecentric.ai are currently working on developing a free online course about machine learning and deep learning. As part of this course, I am developing a series of videos about machine learning basics - the first video in this series was about Random Forests.
You can find the video on YouTube but as of now, it is only available in German. Same goes for the slides, which are also currently German only.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         73 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/autumn-2789234_1920.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" integrity="sha256-IFHWFEbU2/+wNycDECKgjIRSirRNIDp2acEB5fvdVRU=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js" integrity="sha256-+mpyNVJsNt4rVXCw0F+pAOiB3YxmHgrbJsx4ecPuUaI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js" integrity="sha256-vMxgR/7FtLovVA+IPrR7+xTgIgARH7y9VZQnmmi0HDI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js" integrity="sha256-N0qFUh7/9vLvia87dDndewmsgsyYoNkdA212tPc+2NI=" crossorigin="anonymous"></script>


<script src="/js/script-kr8dyqj6rb6ortyib7whfo9x9p6td6zo8t1v4fdz4ecx5kwybsdlmk1slygn.min.js"></script>


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>

  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/11\/how_cnns_learn\/';
          
            this.page.identifier = '\/2018\/11\/how_cnns_learn\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'shirinsplayground';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

