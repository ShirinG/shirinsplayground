<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Shirin&#39;s playgRound</title>
    <link>https://shirinsplayground.netlify.com/categories/machine-learning/</link>
    <description>Recent content in machine learning on Shirin&#39;s playgRound</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Jan 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://shirinsplayground.netlify.com/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How do Convolutional Neural Nets (CNNs) learn? &#43; Keras example</title>
      <link>https://shirinsplayground.netlify.com/2019/01/how_cnns_learn/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2019/01/how_cnns_learn/</guid>
      <description>As with the other videos from our codecentric.ai Bootcamp (Random Forests, Neural Nets &amp;amp; Gradient Boosting), I am again sharing an English version of the script (plus R code) for this most recent addition on How Convolutional Neural Nets work.
In this lesson, I am going to explain how computers learn to see; meaning, how do they learn to recognize images or object on images? One of the most commonly used approaches to teach computers “vision” are Convolutional Neural Nets.</description>
    </item>
    
    <item>
      <title>Machine Learning Basics - Gradient Boosting &amp; XGBoost</title>
      <link>https://shirinsplayground.netlify.com/2018/11/ml_basics_gbm/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/11/ml_basics_gbm/</guid>
      <description>In a recent video, I covered Random Forests and Neural Nets as part of the codecentric.ai Bootcamp.
In the most recent video, I covered Gradient Boosting and XGBoost.
You can find the video on YouTube and the slides on slides.com. Both are again in German with code examples in Python.
But below, you find the English version of the content, plus code examples in R for caret, xgboost and h2o.</description>
    </item>
    
    <item>
      <title>&#39;How do neural nets learn?&#39; A step by step explanation using the H2O Deep Learning algorithm.</title>
      <link>https://shirinsplayground.netlify.com/2018/11/neural_nets_explained/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/11/neural_nets_explained/</guid>
      <description>In my last blogpost about Random Forests I introduced the codecentric.ai Bootcamp. The next part I published was about Neural Networks and Deep Learning. Every video of our bootcamp will have example code and tasks to promote hands-on learning. While the practical parts of the bootcamp will be using Python, below you will find the English R version of this Neural Nets Practical Example, where I explain how neural nets learn and how the concepts and techniques translate to training neural nets in R with the H2O Deep Learning function.</description>
    </item>
    
    <item>
      <title>Machine Learning Basics - Random Forest</title>
      <link>https://shirinsplayground.netlify.com/2018/10/ml_basics_rf/</link>
      <pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/10/ml_basics_rf/</guid>
      <description>A few colleagues of mine and I from codecentric.ai are currently working on developing a free online course about machine learning and deep learning. As part of this course, I am developing a series of videos about machine learning basics - the first video in this series was about Random Forests.
You can find the video on YouTube but as of now, it is only available in German. Same goes for the slides, which are also currently German only.</description>
    </item>
    
    <item>
      <title>Code for Workshop: Introduction to Machine Learning with R</title>
      <link>https://shirinsplayground.netlify.com/2018/06/intro_to_ml_workshop_heidelberg/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/06/intro_to_ml_workshop_heidelberg/</guid>
      <description>These are the slides from my workshop: Introduction to Machine Learning with R which I gave at the University of Heidelberg, Germany on June 28th 2018. The entire code accompanying the workshop can be found below the video.
The workshop covered the basics of machine learning. With an example dataset I went through a standard machine learning workflow in R with the packages caret and h2o:
 reading in data exploratory data analysis missingness feature engineering training and test split model training with Random Forests, Gradient Boosting, Neural Nets, etc.</description>
    </item>
    
    <item>
      <title>Comparing dependencies of popular machine learning packages with `pkgnet`</title>
      <link>https://shirinsplayground.netlify.com/2018/04/pkgnet/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/04/pkgnet/</guid>
      <description>When looking through the CRAN list of packages, I stumbled upon this little gem:
 pkgnet is an R library designed for the analysis of R libraries! The goal of the package is to build a graph representation of a package and its dependencies.
 And I thought it would be fun to play around with it. The little analysis I ended up doing was to compare dependencies of popular machine learning packages.</description>
    </item>
    
    <item>
      <title>Update: Can we predict flu outcome with Machine Learning in R?</title>
      <link>https://shirinsplayground.netlify.com/2018/04/flu_prediction/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/04/flu_prediction/</guid>
      <description>Since I migrated my blog from Github Pages to blogdown and Netlify, I wanted to start migrating (most of) my old posts too - and use that opportunity to update them and make sure the code still works.
Here I am updating my very first machine learning post from 27 Nov 2016: Can we predict flu deaths with Machine Learning and R?. Changes are marked as bold comments.
The main changes I made are:</description>
    </item>
    
    <item>
      <title>I talk about machine learning with Daniel Mies (Podcast in German, though)</title>
      <link>https://shirinsplayground.netlify.com/2018/02/herr_mies_wills_wissen/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/02/herr_mies_wills_wissen/</guid>
      <description>For those of you out there who speak German:
I was interviewed for a tech podcast where I talked about machine learning, neural nets, why I love R and Rstudio and how I became a Data Scientist.
You can download and listen to the podcast here: https://mies.me/2018/01/31/hmww17-machine-learning-mit-dr-shirin-glander/
  In der aktuellen Episode gibt Dr. Shirin Glander (Twitter, Homepage) uns ein paar Einblicke in das Thema Machine Learning. Wir klären zunächst, was Machine Learning ist und welche Möglichkeiten es bietet bevor wir etwas mehr in die Tiefe gehen.</description>
    </item>
    
    <item>
      <title>Looking beyond accuracy to improve trust in machine learning</title>
      <link>https://shirinsplayground.netlify.com/2018/01/looking_beyond_accuracy_to_improve_trust_in_ml/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2018/01/looking_beyond_accuracy_to_improve_trust_in_ml/</guid>
      <description>I have written another blogpost about Looking beyond accuracy to improve trust in machine learning at my company codecentric&amp;rsquo;s blog:
 Traditional machine learning workflows focus heavily on model training and optimization; the best model is usually chosen via performance measures like accuracy or error and we tend to assume that a model is good enough for deployment if it passes certain thresholds of these performance criteria. Why a model makes the predictions it makes, however, is generally neglected.</description>
    </item>
    
    <item>
      <title>Data Science for Fraud Detection</title>
      <link>https://shirinsplayground.netlify.com/2017/09/data-science-fraud-detection/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://shirinsplayground.netlify.com/2017/09/data-science-fraud-detection/</guid>
      <description>I have written the following post about Data Science for Fraud Detection at my company codecentric&amp;rsquo;s blog:
 Fraud can be defined as “the crime of getting money by deceiving people” (Cambridge Dictionary); it is as old as humanity: whenever two parties exchange goods or conduct business there is the potential for one party scamming the other. With an ever increasing use of the internet for shopping, banking, filing insurance claims, etc.</description>
    </item>
    
  </channel>
</rss>
