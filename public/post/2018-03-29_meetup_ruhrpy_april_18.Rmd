---
title: "My upcoming meetup talks about Deep Learning with Keras and explaining complex Machine Learning Models with LIME"
draft: false
author: Shirin Glander
date: '2018-03-28'
categories: [R, meetup, keras]
tags: [R, meetup, keras, deep learning, machine learning, neural nets]
thumbnailImagePosition: left
thumbnailImage: https://secure.meetupstatic.com/s/img/5455565085016210254/logo/svg/logo--script.svg
metaAlignment: center
coverMeta: out
slug: meetup_talk_ruhrpy_april_18
---

I'll be talking about Deep Learning with Keras in R and Python at the following upcoming meetup:

- [Ruhr.Py 2018](https://www.meetup.com/Ruhr-py/events/248093628/) on Wednesday, April 4th

> Introducing Deep Learning with Keras and Python
Keras is a high-level API written in Python for building and prototyping neural networks. It can be used on top of TensorFlow, Theano or CNTK. In this talk we build, train and visualize a Model using Python and Keras - all interactive with Jupyter Notebooks!

---

And I'll be talking about explaining complex Machine Learning Models with LIME at this upcoming meetup:

- [Data Science Meetup Hamburg](https://www.meetup.com/Hamburg-Data-Science-Meetup/events/244145443/) on Thursday, April 12th

> Traditional machine learning workflows focus heavily on model training and optimization; the best model is usually chosen via performance measures like accuracy or error and we tend to assume that a model is good enough for deployment if it passes certain thresholds of these performance criteria. Why a model makes the predictions it makes, however, is generally neglected. But being able to understand and interpret such models can be immensely important for improving model quality, increasing trust and transparency and for reducing bias. Because complex machine learning models are essentially black boxes and too complicated to understand, we need to use approximations to get a better sense of how they work. One such approach is LIME, which stands for Local Interpretable Model-agnostic Explanations and is a tool that helps understand and explain the decisions made by complex machine learning models.

> Dr. Shirin Glander is Data Scientist at codecentric AG. She has received a PhD in Bioinformatics and applies methods of analysis and visualization from different areas - for instance, machine learning, classical statistics, text mining, etc. -to extract and leverage information from data.

![](https://secure.meetupstatic.com/s/img/5455565085016210254/logo/svg/logo--script.svg)